{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "1. Extract/organize line configuration and conduit configuration data from old_exhibit\n",
    "2. Write pdf_comparison class\n",
    "3. Write pdf_markup class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pdfminer.six\n",
    "%pip install pdfplumber\n",
    "%pip install numpy pandas\n",
    "%pip install textdistance\n",
    "%pip install regex\n",
    "%pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_pages, extract_text\n",
    "from pdfminer.layout import LTTextContainer, LTChar, LTRect, LTFigure\n",
    "# To extract text from tables in PDF\n",
    "import pdfplumber\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Iterable, Dict, Tuple\n",
    "import regex\n",
    "from textdistance import hamming, jaro, levenshtein\n",
    "import yaml\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from io import StringIO\n",
    "\n",
    "# from pdfminer.converter import TextConverter\n",
    "# from pdfminer.layout import LAParams\n",
    "# from pdfminer.pdfdocument import PDFDocument\n",
    "# from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "# from pdfminer.pdfpage import PDFPage\n",
    "# from pdfminer.pdfparser import PDFParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pdf_data():\n",
    "    def __init__(self,   \n",
    "                 orig_filepath: str | Path, \n",
    "                 ocr_filepath:  str | Path, \n",
    "                 config:        str | Path,\n",
    "                 key_val_sep:   str = ':' ,) -> None:\n",
    "        self.orig_filepath = orig_filepath\n",
    "        self.ocr_filepath = ocr_filepath\n",
    "        self.config = config  \n",
    "        self.text_df = None  \n",
    "        self.px_col_sep = 8\n",
    "        self.px_word_sep = 2\n",
    "        self.col_sep_str = ' | '\n",
    "        self.key_val_sep = key_val_sep\n",
    "\n",
    "    def combine_key_value_pairs_in_words_df(self, words_df):\n",
    "        drop_idxs = list()\n",
    "        for wIdx, word in words_df.iterrows():\n",
    "            test = (word['text'][-1] == self.key_val_sep) and \\\n",
    "                    (wIdx != words_df.index[-1]) and \\\n",
    "                    (words_df.loc[wIdx+1, 'top'] == word['top'])  \n",
    "            if test:\n",
    "                drop_idxs.append(wIdx+1)\n",
    "                words_df.loc[wIdx, 'text'] = f\"{word['text']}{words_df.loc[wIdx+1, 'text']}\"  \n",
    "                words_df.loc[wIdx, 'right'] = words_df.loc[wIdx+1, 'right']       \n",
    "        words_df = words_df.drop(drop_idxs).reset_index(drop=True)    \n",
    "\n",
    "        return words_df\n",
    "\n",
    "    def fill_implicit_keys(self, section_header, left_mult=2, right_mult=2):\n",
    "        section_dict = self.sections[section_header]\n",
    "        for sub_idx, subsection_bounds in section_dict['bounds'].iterrows():    \n",
    "            mask = (self.text_df['norm_y_top'   ] > subsection_bounds['y_top'   ]) & \\\n",
    "                   (self.text_df['norm_y_bottom'] < subsection_bounds['y_bottom']) \n",
    "            subsect_df = self.text_df.loc[mask, :]\n",
    "\n",
    "            if any(subsect_df['source'] == 'ocr'):\n",
    "                page = pdfplumber.open(self.ocr_filepath ).pages[subsect_df.loc[subsect_df.index[0], 'page']]\n",
    "            else:\n",
    "                page = pdfplumber.open(self.orig_filepath).pages[subsect_df.loc[subsect_df.index[0], 'page']]\n",
    "            \n",
    "            words_df = self.get_words_df(page, subsect_df['y_top'].min(), subsect_df['y_bottom'].max())\n",
    "            words_df.loc[:, 'top'] = np.round(words_df['top']) \n",
    "            words_df.sort_values(by=['top', 'left'], ignore_index=True, inplace=True)   \n",
    "\n",
    "            words_df = self.combine_key_value_pairs_in_words_df(words_df)\n",
    "\n",
    "            split_lines     = list()\n",
    "            split_lines_row = list()\n",
    "            split_lines_col = list()\n",
    "            drop_idxs = list()\n",
    "            for rIdx, line in subsect_df.iterrows():\n",
    "                text_by_col = line['text'].split(self.col_sep_str)\n",
    "                split_lines.extend(text_by_col)\n",
    "                split_lines_row.extend([rIdx for k in range(len(text_by_col))])\n",
    "                split_lines_col.extend(list(range(len(text_by_col))))\n",
    "                \n",
    "                # combine words_df to match phrases in split_lines\n",
    "                for tIdx, token in enumerate(text_by_col):\n",
    "                    combine_idxs = [idx for idx, word in words_df.iterrows() \n",
    "                                    if  word['text'] in token\n",
    "                                    and word['top']+0.5 >= line['y_top']\n",
    "                                    and word['bottom'] <= line['y_bottom']]\n",
    "                    tmp_df = words_df.loc[combine_idxs, :]\n",
    "                    \n",
    "                    first_word = token.split(' ')[0]\n",
    "                    possible_start_idx = tmp_df.index[tmp_df['text'] == first_word]\n",
    "                    for start_idx in possible_start_idx:\n",
    "                        phrase_idxs = range(start_idx, start_idx+len(token.split(' ')))\n",
    "                        if all([True if idx in tmp_df.index else False for idx in phrase_idxs]): \n",
    "                            phrase = ' '.join(tmp_df.loc[phrase_idxs, 'text'])\n",
    "                            if phrase == token:\n",
    "                                words_df.loc[start_idx, ['text', 'right']] = [phrase, tmp_df.loc[phrase_idxs[-1], 'right']]\n",
    "                                drop_idxs.extend(phrase_idxs[1:])             \n",
    "                                break                                  \n",
    "            words_df = words_df.drop(drop_idxs).reset_index(drop=True)\n",
    "\n",
    "            assert all([True if phrase==token else False for phrase, token in zip(split_lines, words_df['text'])])\n",
    "\n",
    "            for token, rIdx, cIdx, (wIdx, word) in zip(split_lines, split_lines_row, split_lines_col, words_df.iterrows()):\n",
    "                if self.key_val_sep in token:\n",
    "                    continue\n",
    "                token_bounds = word[['left', 'right']]\n",
    "                col_mask = ((words_df['right' ]- token_bounds['left'] > -left_mult*self.px_col_sep) & \\\n",
    "                            (words_df['left' ] - token_bounds['left'] <=  0                )) | \\\n",
    "                           ((words_df['right'] - token_bounds['right'] < right_mult*self.px_col_sep) & \\\n",
    "                            (words_df['right'] - token_bounds['right'] >= 0                ))\n",
    "                same_column_tokens = words_df.loc[col_mask, 'text']\n",
    "                \n",
    "                implicit_key = [item.split(self.key_val_sep)[0] for item in same_column_tokens.values if len(item.split(self.key_val_sep)) == 2]\n",
    "                if len(implicit_key) >= 1:\n",
    "                    original_text = self.text_df.loc[rIdx, 'text']\n",
    "                    text_cols = original_text.split(self.col_sep_str)\n",
    "                    text_cols[cIdx] = f'{implicit_key[0]}{self.key_val_sep}{text_cols[cIdx]}'\n",
    "                    self.text_df.loc[rIdx, 'text'] = self.col_sep_str.join(text_cols)  \n",
    "\n",
    "    def identify_line_merge_sets(self):\n",
    "        merge_sets = list()\n",
    "        for idx, line in self.text_df.iterrows():\n",
    "            merge_set = np.where((self.text_df['norm_y_top']    < line['norm_y_bottom']) &\n",
    "                                 (self.text_df['norm_y_top']    > line['norm_y_top']   )  )[0]\n",
    "            merge_set = self.text_df.index[merge_set]\n",
    "            if len(merge_set) > 0:\n",
    "                merge_set = [idx] + merge_set.to_list()\n",
    "                same_merge_set   = any([True if m_set == merge_set else False for m_set in merge_sets])\n",
    "                overlapping_sets = [set_idx for set_idx, m_set in enumerate(merge_sets) if any(i for i in m_set if i in merge_set)]\n",
    "                if same_merge_set:\n",
    "                    continue\n",
    "                elif len(overlapping_sets) == 1:\n",
    "                    merge_sets[overlapping_sets[0]] = np.unique(merge_sets[overlapping_sets[0]] + merge_set).tolist() \n",
    "                elif len(overlapping_sets) > 1:\n",
    "                    print('Have not written code to manage more than one overlapping set when combining lines')\n",
    "                else:\n",
    "                    merge_sets.append(merge_set)\n",
    "        return merge_sets\n",
    "    \n",
    "    def get_words_df(self, page, y_top, y_bottom):\n",
    "        page_crop = page.within_bbox((         0, y_top, \n",
    "                                        page.width, y_bottom))  \n",
    "\n",
    "        words = page_crop.extract_words()  \n",
    "        words_dict = dict(text=[], left=[], right=[], top=[], bottom=[])\n",
    "        for word in words:\n",
    "            if word['text'] == '|':\n",
    "                continue\n",
    "            word['text'] = word['text'].lower().replace('|','')\n",
    "            for dict_key, word_key in zip(['text', 'left', 'right', 'top', 'bottom'],\n",
    "                                            ['text',   'x0',    'x1', 'top', 'bottom']):\n",
    "                words_dict[dict_key].append(word[word_key])\n",
    "        \n",
    "        words_df = pd.DataFrame.from_dict(words_dict)\n",
    "        words_df.sort_values(by='left', ignore_index=True, inplace=True)\n",
    "\n",
    "        return words_df\n",
    "\n",
    "    def identify_columns_from_words_df(self, words_df):\n",
    "        col_id = []\n",
    "        col_num = 0\n",
    "        prev_w_info = None\n",
    "        for w_idx, w_info in words_df.iterrows():\n",
    "            if prev_w_info is not None: \n",
    "                if (w_info['left'] - prev_w_info['right'] > self.px_col_sep):\n",
    "                    col_num += 1\n",
    "                elif (w_info['left'] - prev_w_info['right'] < 0):\n",
    "                    w_info['right'] = prev_w_info['right'] \n",
    "            col_id.append(col_num)\n",
    "            prev_w_info = w_info.copy()\n",
    "        words_df['col_id'] = col_id\n",
    "        words_df.sort_values(by=['col_id', 'top', 'left'], ignore_index=True, inplace=True)\n",
    "\n",
    "        col_phrases = []\n",
    "        for col_id in words_df['col_id'].unique():\n",
    "            col_df = words_df.loc[words_df['col_id'] == col_id, :]\n",
    "            col_phrases.append(' '.join(col_df['text']))\n",
    "\n",
    "        return col_phrases \n",
    "\n",
    "    def organize_single_lines(self, merge_sets, ocr_pdf, orig_pdf):\n",
    "        merge_list = list(itertools.chain.from_iterable(merge_sets))\n",
    "        for idx, line in self.text_df.iterrows():\n",
    "            if idx not in merge_list:   \n",
    "                if line['source'] == 'ocr':\n",
    "                    page = ocr_pdf.pages [line['page']]\n",
    "                else:\n",
    "                    page = orig_pdf.pages[line['page']]\n",
    "\n",
    "                words_df = self.get_words_df(page, line['y_top'], line['y_bottom'])\n",
    "                words_df.loc[:, 'top'] = np.round(words_df['top']) \n",
    "\n",
    "                words_df = self.combine_key_value_pairs_in_words_df(words_df)\n",
    "\n",
    "                col_phrases = self.identify_columns_from_words_df(words_df)\n",
    "\n",
    "                self.text_df.loc[idx, 'text'] = self.col_sep_str.join(col_phrases)\n",
    "\n",
    "    def combine_merge_sets(self, merge_sets, ocr_pdf, orig_pdf):\n",
    "\n",
    "        drop_idxs = list()\n",
    "        for merge_set in merge_sets:\n",
    "            partial_df = self.text_df.loc[merge_set, :]\n",
    "            y_top    = partial_df['y_top'].min()    \n",
    "            y_bottom = partial_df['y_bottom'].max()\n",
    "\n",
    "            if any(partial_df['source'] == 'ocr'):\n",
    "                page = ocr_pdf.pages [partial_df.loc[merge_set[0], 'page']]\n",
    "            else:\n",
    "                page = orig_pdf.pages[partial_df.loc[merge_set[0], 'page']]\n",
    "\n",
    "            words_df = self.get_words_df(page, y_top, y_bottom)\n",
    "            \n",
    "            col_phrases = self.identify_columns_from_words_df(words_df)\n",
    "\n",
    "            # replace first line in merge set with merged text and position info, then store indices of \n",
    "            # remaining merge set to drop at end of combine method\n",
    "            self.text_df.loc[merge_set[0], \n",
    "                             ['text', 'y_bottom', 'x_left', 'x_right', 'norm_y_bottom',]] = [self.col_sep_str.join(col_phrases),\n",
    "                                                                                             partial_df['y_bottom'].max(),\n",
    "                                                                                             partial_df['x_left'].min(),\n",
    "                                                                                             partial_df['x_right'].max(),\n",
    "                                                                                             partial_df['norm_y_bottom'].max(),] \n",
    "\n",
    "            drop_idxs.extend(merge_set[1:])             \n",
    "\n",
    "        self.text_df = self.text_df.drop(drop_idxs).reset_index(drop=True)\n",
    "\n",
    "    def organize_text_lines_by_row_and_column(self):\n",
    "        merge_sets = self.identify_line_merge_sets()\n",
    "        ocr_pdf  = pdfplumber.open(self.ocr_filepath)\n",
    "        orig_pdf = pdfplumber.open(self.orig_filepath) \n",
    "        self.organize_single_lines(merge_sets, ocr_pdf, orig_pdf)\n",
    "        self.combine_merge_sets   (merge_sets, ocr_pdf, orig_pdf)\n",
    "    \n",
    "    def split_text_lines_with_pdfplumber(self, pdf, element, page_idx, text_dict,):\n",
    "        did_split = False\n",
    "        page = pdf.pages[page_idx]\n",
    "        page_crop = page.within_bbox((         0, page.height - element.y1, \n",
    "                                      page.width, page.height - element.y0))  \n",
    "\n",
    "        text = page_crop.extract_text_lines()\n",
    "        \n",
    "        if len(text) > 1:\n",
    "            did_split = True\n",
    "            for line in text:\n",
    "\n",
    "                norm_y_top    = page_idx + (line['top'   ] / page.height)\n",
    "                norm_y_bottom = page_idx + (line['bottom'] / page.height)\n",
    "                if np.logical_not(np.any((np.isclose(self.text_df['norm_y_top'   ], norm_y_top   , atol=1e-2)) &\n",
    "                                         (np.isclose(self.text_df['norm_y_bottom'], norm_y_bottom, atol=1e-2))  )):\n",
    "                    text_dict['page'         ].append(page_idx)\n",
    "                    text_dict['y_bottom'     ].append(line['bottom'])\n",
    "                    text_dict['y_top'        ].append(line['top'])\n",
    "                    text_dict['x_left'       ].append(line['x0'])\n",
    "                    text_dict['x_right'      ].append(line['x1'])\n",
    "                    text_dict['text'         ].append(line['text'].lower().replace('|', ''))\n",
    "                    text_dict['norm_y_top'   ].append(norm_y_top)\n",
    "                    text_dict['norm_y_bottom'].append(norm_y_bottom)\n",
    "                    text_dict['source'       ].append('ocr')\n",
    "\n",
    "                    print(f'\\nstoring text from OCR on page {page_idx}:\\n\"{line['text'].lower()}\"')\n",
    "\n",
    "        return did_split    \n",
    "\n",
    "    def get_text_lines_from_original(self):\n",
    "        pdf = pdfplumber.open(self.orig_filepath)\n",
    "        text_dict = dict(text=[], source=[], page=[], y_top=[], y_bottom=[], x_left=[], x_right=[], norm_y_top=[], norm_y_bottom=[],)\n",
    "        for page_idx, page in enumerate(pdf.pages):\n",
    "            text_lines = page.extract_text_lines()\n",
    "            for line in text_lines:\n",
    "                norm_y_top    = page_idx + (line['top'   ] / page.height)\n",
    "                norm_y_bottom = page_idx + (line['bottom'] / page.height)\n",
    "\n",
    "                text_dict['page'         ].append(page_idx)\n",
    "                text_dict['y_bottom'     ].append(line['bottom'])\n",
    "                text_dict['y_top'        ].append(line['top'])\n",
    "                text_dict['x_left'       ].append(line['x0'])\n",
    "                text_dict['x_right'      ].append(line['x1'])\n",
    "                text_dict['text'         ].append(line['text'].lower().replace('|', ''))\n",
    "                text_dict['norm_y_top'   ].append(norm_y_top)\n",
    "                text_dict['norm_y_bottom'].append(norm_y_bottom)\n",
    "                text_dict['source'       ].append('original')\n",
    "        \n",
    "        if self.text_df is None:\n",
    "            self.text_df = pd.DataFrame(text_dict)\n",
    "        else:\n",
    "            tmp_text_df = pd.DataFrame(text_dict)\n",
    "            self.text_df = pd.concat((self.text_df, tmp_text_df), axis=0, ignore_index=True)\n",
    "\n",
    "        self.text_df.sort_values(by='norm_y_top', inplace=True, ignore_index=True, ascending=True)\n",
    "\n",
    "    def get_text_lines_from_ocr(self, pages: Optional[Iterable[int]] = None) -> pd.DataFrame:\n",
    "        text_dict = dict(text=[], source=[], page=[], y_top=[], y_bottom=[], x_left=[], x_right=[], norm_y_top=[], norm_y_bottom=[],)\n",
    "        for page_idx, page in enumerate(extract_pages(self.ocr_filepath)):\n",
    "            pdf = pdfplumber.open(self.ocr_filepath)\n",
    "            for el_idx, element in enumerate(page):\n",
    "                if isinstance(element, LTTextContainer):\n",
    "                    did_split = self.split_text_lines_with_pdfplumber(pdf, element, page_idx, text_dict)\n",
    "                    if not did_split:\n",
    "                        y_top = page.height - element.y1\n",
    "                        y_bottom = page.height - element.y0 \n",
    "                        norm_y_top    = page_idx + y_top    / page.height\n",
    "                        norm_y_bottom = page_idx + y_bottom / page.height\n",
    "                        if np.logical_not(np.any((np.isclose(self.text_df['norm_y_top'   ], norm_y_top   , atol=1e-2)) &\n",
    "                                                 (np.isclose(self.text_df['norm_y_bottom'], norm_y_bottom, atol=1e-2))  )):\n",
    "                            text_dict['page'         ].append(page_idx)\n",
    "                            text_dict['y_bottom'     ].append(y_bottom)\n",
    "                            text_dict['y_top'        ].append(y_top)\n",
    "                            text_dict['x_left'       ].append(element.x0)\n",
    "                            text_dict['x_right'      ].append(element.x1)\n",
    "                            text_dict['text'         ].append(element.get_text().lower().replace('\\n', '').replace('|', ''))\n",
    "                            text_dict['norm_y_top'   ].append(norm_y_top)\n",
    "                            text_dict['norm_y_bottom'].append(norm_y_bottom)\n",
    "                            text_dict['source'       ].append('ocr')\n",
    "    \n",
    "                            print(f'\\nstoring text from OCR on page {page_idx}:\\n\"{element.get_text().lower().replace('\\n', '')}\"')\n",
    "\n",
    "                elif isinstance(element, LTRect):\n",
    "                    print(f'page = {page_idx}, ypos={element.y0}, type={type(element)}')\n",
    "                else:\n",
    "                    print(f'page = {page_idx}, ypos={element.y0}, type={type(element)}')\n",
    "\n",
    "        if self.text_df is None:\n",
    "            self.text_df = pd.DataFrame(text_dict)\n",
    "        elif len(text_dict['text']) > 0:\n",
    "            tmp_text_df  = pd.DataFrame(text_dict)\n",
    "            self.text_df = pd.concat((self.text_df, tmp_text_df), axis=0, ignore_index=True)\n",
    "\n",
    "        self.text_df.sort_values(by='norm_y_top', inplace=True, ignore_index=True, ascending=True)\n",
    "\n",
    "    def get_section_headers(self):\n",
    "        with open(self.config, 'r') as file:\n",
    "            self.config_data = yaml.safe_load(file) \n",
    "        \n",
    "        self.sections = dict()\n",
    "        for section in self.config_data['sections']:\n",
    "            self.sections[section['header']] = dict(bounds = pd.DataFrame(),\n",
    "                                                    extract = section['extract'])\n",
    "            for key in section.keys():\n",
    "                if key in ['header', 'extract']: continue\n",
    "                self.sections[section['header']][key] = section[key]\n",
    "\n",
    "    def get_section_bounds(self):\n",
    "\n",
    "        self.get_section_headers()\n",
    "\n",
    "        # detect start and end of sections\n",
    "        prev_section_info = dict(header=None, df_row=None)\n",
    "        prev_page = 0\n",
    "        for row_idx, text_data in self.text_df.iterrows():\n",
    "            detected_section = None\n",
    "            for header in self.sections.keys():\n",
    "                match = regex.search(f'{header}{{s<=3,i<=3,d<=3}}', text_data['text'], regex.BESTMATCH)    \n",
    "                if match is not None:\n",
    "                    detected_section = header\n",
    "                    break\n",
    "\n",
    "            if text_data['page'] > prev_page or detected_section is not None:\n",
    "                if prev_section_info['header'] is not None:   # store end of sections\n",
    "                    prev_df_idx = self.sections[prev_section_info['header']]['bounds'].index[-1] \n",
    "                    prev_bottom = prev_page+0.9999 if (text_data['page'] > prev_page) else text_data['norm_y_top'] \n",
    "                    self.sections[prev_section_info['header']]['bounds'].loc[prev_df_idx, ['y_bottom',]] = [prev_bottom]\n",
    "                # store start of sections\n",
    "                top = text_data['page'] if (text_data['page'] > prev_page) else text_data['norm_y_top']\n",
    "                tmp_df = pd.DataFrame(data    = zip([top], [np.nan], [False]),\n",
    "                                      columns = ['y_top', 'y_bottom', 'data_extracted'],)\n",
    "                header = detected_section\n",
    "                self.sections[header]['bounds'] = pd.concat((self.sections[header]['bounds'], tmp_df), ignore_index=True)\n",
    "                prev_section_info['header'] = header\n",
    "                if text_data['page'] > prev_page:\n",
    "                    prev_page+=1\n",
    "            prev_section_info['df_row'] = row_idx\n",
    "        \n",
    "        # store end of final section\n",
    "        prev_y_bottom = self.text_df.loc[prev_section_info['df_row'], 'norm_y_bottom']\n",
    "        prev_df_idx = self.sections[prev_section_info['header']]['bounds'].index[-1] \n",
    "        self.sections[prev_section_info['header']]['bounds'].loc[prev_df_idx, ['y_bottom',]] = [np.ceil(prev_y_bottom),]\n",
    "    \n",
    "    def extract_table(self, subsection_bounds):  \n",
    "        page_num = int(np.floor(subsection_bounds['y_top'])) \n",
    "        pdf = pdfplumber.open(self.orig_filepath)\n",
    "        table_page = pdf.pages[page_num]\n",
    "        table_crop = table_page.within_bbox((               0, (subsection_bounds['y_top'   ]-page_num)*table_page.height, \n",
    "                                             table_page.width, (subsection_bounds['y_bottom']-page_num)*table_page.height))\n",
    "        table = table_crop.extract_table()\n",
    "        # print((subsection_bounds['y_top'   ]-page_num)*table_page.height, (subsection_bounds['y_bottom']-page_num)*table_page.height, table)\n",
    "        return table\n",
    "    \n",
    "    def extract_text_lines_from_original(self, subsection_bounds):\n",
    "        page_num = int(np.floor(subsection_bounds['y_top'])) \n",
    "        pdf = pdfplumber.open(self.orig_filepath)\n",
    "        page = pdf.pages[page_num]\n",
    "        page_crop = page.within_bbox((         0, (subsection_bounds['y_top'   ]-page_num)*page.height, \n",
    "                                      page.width, (subsection_bounds['y_bottom']-page_num)*page.height))  \n",
    "\n",
    "        text = page_crop.extract_text_lines()\n",
    "\n",
    "        for line in text:\n",
    "            line['norm_y_top']    = page_num + (line['top']    / page.height)\n",
    "            line['norm_y_bottom'] = page_num + (line['bottom'] / page.height)\n",
    "            line['page']          = page_num\n",
    "            line['y_bottom']      = page.height - line['bottom']\n",
    "            line['y_top']         = page.height - line['top']\n",
    "            line['text'] = line['text'].lower().replace('|', '')\n",
    "\n",
    "        return text  \n",
    "\n",
    "    def table_to_df(self, \n",
    "                    table: List[List[str]], \n",
    "                    extract_params: str | Dict | List[Dict],\n",
    "                    ) -> pd.DataFrame:\n",
    "        if type(extract_params) == str and 'col' in extract_params.lower():\n",
    "            info_keys = list()\n",
    "            data = list()\n",
    "            for row in table:\n",
    "                iKey = row.pop(0)\n",
    "                info_keys.append(iKey.replace('\\n', ' '))\n",
    "                data.append(row)\n",
    "            df = pd.DataFrame(data=np.array(data).transpose(), columns=info_keys)\n",
    "\n",
    "        elif type(extract_params) == str and 'row' in extract_params.lower():\n",
    "            info_keys = table[0]\n",
    "            data = table[1:]\n",
    "            df = pd.DataFrame(data=data, columns=info_keys)\n",
    "\n",
    "        else:\n",
    "            print('There is no method implemented for converting data with this extraction method to a DataFrame')\n",
    "            df = None\n",
    "        \n",
    "        return df \n",
    " \n",
    "    def extract_table_data(self):\n",
    "        for section_header, section_dict in self.sections.items():\n",
    "            for sub_idx, subsection_bounds in section_dict['bounds'].iterrows():\n",
    "                if subsection_bounds['data_extracted']:\n",
    "                    continue\n",
    "\n",
    "                table = self.extract_table(subsection_bounds)\n",
    "                if table is not None:\n",
    "                    data_df = self.table_to_df(table, section_dict['extract'])\n",
    "                    data_df = data_df.loc[:, [col for col in data_df.columns if col.lower() != section_header]]\n",
    "                    if 'data' in section_dict.keys(): \n",
    "                        section_dict['data'] = pd.concat((section_dict['data'], data_df),\n",
    "                                                         axis=0,\n",
    "                                                         ignore_index=True)\n",
    "                    else:\n",
    "                        section_dict['data'] = data_df\n",
    "                    \n",
    "                    section_dict['bounds'].loc[sub_idx, 'data_extracted'] = True\n",
    "\n",
    "    def align_data_to_existing_df(self,\n",
    "                                  section_dict: Dict,\n",
    "                                  subsect_df: pd.DataFrame,\n",
    "                                 ):\n",
    "        if type(section_dict['extract']) == str and 'col' in section_dict['extract'].lower():\n",
    "            info_keys_to_match = list(section_dict['data'].columns)\n",
    "            original_info_keys = list(section_dict['data'].columns)\n",
    "            info_keys = list()\n",
    "            data      = list()\n",
    "            for text in subsect_df['text']:\n",
    "                row = text.split(self.col_sep_str)\n",
    "                iKey = row.pop(0)\n",
    "                iKey = iKey.replace('\\n', ' ')\n",
    "                match_score = np.array([levenshtein.normalized_similarity(iKey, matchKey) for matchKey in info_keys_to_match])\n",
    "                sorted_match_score, sorted_info_keys = zip(*sorted(zip(match_score, info_keys_to_match), reverse=True))\n",
    "                if iKey == 'equipment tip':\n",
    "                    stop = []\n",
    "                try:\n",
    "                    top_key_matches = sorted_info_keys[:3]\n",
    "                    \n",
    "                    #correct any instances in which OCR dropped the last word (probably b/c it was on a second line), causing poor matching\n",
    "                    if (len(iKey.split(' ')) == len(top_key_matches[0].split(' ')) \n",
    "                        and any([len(iKey.split(' ')) < len(key.split(' ')) for key in top_key_matches])):\n",
    "                        match_score = np.array([levenshtein.normalized_similarity(iKey, ' '.join(matchKey.split(' ')[:-1])) for matchKey in info_keys_to_match])\n",
    "            \n",
    "                    matched_key = info_keys_to_match.pop(np.where(match_score == match_score.max())[0][0])\n",
    "                    info_keys.append(matched_key)\n",
    "                    data.append(row)\n",
    "                    print(iKey, matched_key)\n",
    "                except:\n",
    "                    print(f'\\nNo matched key: iKey={iKey}, text={text}')\n",
    "            \n",
    "            # Add dummy data for unmatched keys\n",
    "            for key in info_keys_to_match:\n",
    "                info_keys.append(key)\n",
    "                data.append(['data_not_found' for k in range(expected_num_items)])\n",
    "\n",
    "            expected_num_items = pd.Series([len(d) for d in data]).mode()[0]\n",
    "            wrong_count_info = [(idx, len(d)) for idx, d in enumerate(data) if len(d) != expected_num_items]\n",
    "            for idx, num_items in wrong_count_info:\n",
    "                data[idx] = ['wrong_num_columns' for k in range(expected_num_items)]\n",
    "                print(f'\\n\"{info_keys[idx]}\" contained the wrong number of columns in the line.')\n",
    "\n",
    "            correct_order = [np.where(np.array(original_info_keys) == key)[0][0] for key in info_keys]\n",
    "            _, info_keys = zip(*sorted(zip(correct_order, info_keys)))\n",
    "            _, data      = zip(*sorted(zip(correct_order, data))) \n",
    "\n",
    "            data_df = pd.DataFrame(data=np.array(data).transpose(), columns=info_keys)\n",
    "            section_dict['data'] = pd.concat((section_dict['data'], data_df),\n",
    "                                              axis=0,\n",
    "                                              ignore_index=True)\n",
    "        return\n",
    "\n",
    "    def get_multilevel_key_value_pairs(self, section_dict, items):\n",
    "        filling_subheader = False\n",
    "        for item in items: \n",
    "            split_item = item.split(self.key_val_sep)\n",
    "            if len(split_item) == 2:\n",
    "                key, value = split_item\n",
    "                if len(value) == 0:\n",
    "                    value = None\n",
    "                else:\n",
    "                    value = value[1:]  if value[0]  == ' '  else value\n",
    "                    value = value[:-1] if value[-1] == '\\n' else value\n",
    "                    \n",
    "                if filling_subheader:\n",
    "                    section_dict['data'][stored_key][key] = value\n",
    "                    print(f'{stored_key} - {key}{self.key_val_sep} {value}')\n",
    "                else:\n",
    "                    section_dict['data'][key] = value     \n",
    "                    print(f'{key}{self.key_val_sep} {value}')\n",
    "            elif len(split_item) == 1:\n",
    "                stored_key = split_item[0]\n",
    "                section_dict['data'][stored_key] = dict()\n",
    "                filling_subheader = True\n",
    "\n",
    "    def extract_key_value_pairs(self, \n",
    "                                section_dict: Dict, \n",
    "                                subsect_df: pd.DataFrame, \n",
    "                                ) -> Dict:\n",
    "        section_dict['data'] = dict()\n",
    "        for l_idx, line in subsect_df.iterrows(): \n",
    "            items = line['text'].split(self.col_sep_str)\n",
    "            key_value_pairs = [item for item in items if len(item.split(self.key_val_sep)) == 2]\n",
    "            if len(key_value_pairs) == len(items):\n",
    "                for item in key_value_pairs:\n",
    "                    key, value = item.split(self.key_val_sep)\n",
    "                    if len(value) == 0:\n",
    "                        value = None\n",
    "                    else:\n",
    "                        value = value[1:]  if value[0]  == ' '  else value\n",
    "                        value = value[:-1] if value[-1] == '\\n' else value\n",
    "                    section_dict['data'][key] = value     \n",
    "                    print(f'{key}{self.key_val_sep} {value}') \n",
    "            else:\n",
    "                if line['source'] == 'original':\n",
    "                    pdf = pdfplumber.open(self.orig_filepath)\n",
    "                elif line['source'] == 'ocr':\n",
    "                    pdf = pdfplumber.open(self.ocr_filepath)\n",
    "                self.get_multilevel_key_value_pairs(section_dict, items)\n",
    "\n",
    "    def extract_text_data(self):\n",
    "        for section_header, section_dict in self.sections.items():\n",
    "            for sub_idx, subsection_bounds in section_dict['bounds'].iterrows():\n",
    "                if subsection_bounds['data_extracted']:\n",
    "                    continue\n",
    "\n",
    "                mask = (self.text_df['norm_y_top'   ] > subsection_bounds['y_top'   ]) & \\\n",
    "                       (self.text_df['norm_y_bottom'] < subsection_bounds['y_bottom']) \n",
    "                subsect_df = self.text_df.loc[mask, :]\n",
    "                \n",
    "                if 'data' in section_dict.keys() and type(section_dict['data']) == pd.DataFrame:\n",
    "                    self.align_data_to_existing_df(section_dict, subsect_df)\n",
    "                else:\n",
    "                    self.extract_key_value_pairs(section_dict, subsect_df)\n",
    "                \n",
    "                section_dict['bounds'].loc[sub_idx, 'data_extracted'] = True\n",
    "\n",
    "    def print_text(self):\n",
    "        max_x = 0\n",
    "        for page_text in self.text_containers:\n",
    "            for text_container in page_text:\n",
    "                if text_container.x1 > max_x:\n",
    "                    max_x = text_container.x1\n",
    "        for page_num, page_text in enumerate(self.text_containers):\n",
    "            print('###############################################')\n",
    "            print(f'Page {page_num}')\n",
    "            print('###############################################') \n",
    "            for text_container in page_text:  \n",
    "                text = text_container.get_text()\n",
    "                # print(f'{text_container.y0} to {text_container.y1}', text)\n",
    "                print(text_container.y1, text_container.y0, text)\n",
    "\n",
    "\n",
    "class ATC_amendment(pdf_data):\n",
    "    def __init__(self, \n",
    "                 orig_filepath: str | Path, \n",
    "                 ocr_filepath:  str | Path, \n",
    "                 config:        str | Path,\n",
    "                 key_val_sep:   str = ':' ,) -> None:        \n",
    "        super().__init__(orig_filepath, ocr_filepath, config, key_val_sep)\n",
    "\n",
    "    def extract_line_config_data_from_cells_containing_all_key_value_pairs(self, \n",
    "                                                                           equipment_df, \n",
    "                                                                           configuration_col,\n",
    "                                                                           data_dict, \n",
    "                                                                           data_keys,\n",
    "                                                                           storage_key):\n",
    "        line_config_df = equipment_df.loc[:, configuration_col]\n",
    "        for equipIdx, cell in line_config_df.items():\n",
    "            for dKey in data_keys:\n",
    "                num_match = len(regex.findall(f'{dKey}{{e<=1}}', cell))\n",
    "                \n",
    "                if num_match > 0:\n",
    "                    # move thru each match (there may be multiple line configs in single cell)\n",
    "                    for idx in range(num_match):\n",
    "                        match = regex.search(f'{dKey}{{e<=1}}', cell, pos=idx)\n",
    "                        key_span = match.span()\n",
    "                        \n",
    "                        # find the next key match in the string to know where the value for this key ends\n",
    "                        possible_next_keys_pos = list()\n",
    "                        for next_dKey in data_keys:\n",
    "                            next_key_match = regex.search(f'{next_dKey}{{e<=1}}', cell[key_span[1]:], pos=0) \n",
    "                            if next_key_match is not None:\n",
    "                                possible_next_keys_pos.append(next_key_match.span()[0])\n",
    "                        # extract the data token from the string\n",
    "                        if len(possible_next_keys_pos) == 0:\n",
    "                            data_token = cell[key_span[0] : ]\n",
    "                        else:\n",
    "                            data_token = cell[key_span[0] : key_span[1] + min(possible_next_keys_pos)]\n",
    "                        data_token = data_token[ :-1] if data_token[-1] == '\\n' else data_token\n",
    "                        data_token = data_token.replace('\\n', '')\n",
    "                        print(data_token)\n",
    "                        val = data_token.split(self.key_val_sep)[1]\n",
    "                        val = val[1:] if val[0] == ' ' else val\n",
    "\n",
    "                        data_dict[str(idx)][dKey][equipIdx] = val\n",
    "\n",
    "        for line_num, line_data in data_dict.items():\n",
    "            if any([True if any([True if val is not None else False for val in data_list]) else False \n",
    "                    for tmp_key, data_list in line_data.items()]):\n",
    "                for dKey, values in line_data.items():\n",
    "                    key = f'{storage_key}_{line_num}_{dKey}'\n",
    "                    equipment_df[key] = values \n",
    "        \n",
    "    def extract_line_config_data_from_separated_cells(self, \n",
    "                                                      equipment_df, \n",
    "                                                      configuration_cols,\n",
    "                                                      data_dict, \n",
    "                                                      data_keys,\n",
    "                                                      storage_key):\n",
    "        line_config_df = equipment_df.loc[:, configuration_cols]\n",
    "        for equipIdx, row in line_config_df.iterrows():\n",
    "            for dKey, col in zip(data_dict['0'].keys(), line_config_df.columns):\n",
    "                print(line_config_df.loc[equipIdx, :])\n",
    "                print(f'{dKey}: {row[col]}')        \n",
    "                \n",
    "\n",
    "    def align_line_configuration_data(self, group_key, max_line_types=2, type_key=None): # TODO\n",
    "        \n",
    "        pdf_data_keys    = self.sections['equipment specifications'][f'{group_key} keys']\n",
    "        equipment_df = self.sections['equipment specifications']['data']\n",
    "        \n",
    "        if 'separated' in group_key:\n",
    "            storage_key = f\"{type_key.split(' ')[0]}_config\" \n",
    "            storage_data_keys = [self.sections['equipment specifications'][config_group_key] \n",
    "                                 for config_group_key in self.sections['equipment specifications'].keys() \n",
    "                                 if type_key in config_group_key][0]\n",
    "            configuration_cols = list()\n",
    "            for dKey in pdf_data_keys:\n",
    "                config_col_match_scores = [(col, levenshtein.normalized_similarity(col, dKey)) for col in equipment_df.columns]\n",
    "                scores = np.array([score for _, score in config_col_match_scores])\n",
    "                config_col = config_col_match_scores[np.argmax(scores)][0]    \n",
    "                configuration_cols.append(config_col)\n",
    "        else:\n",
    "            storage_key = f\"{group_key.split(' ')[0]}_config\"\n",
    "            storage_data_keys = pdf_data_keys\n",
    "            configuration_cols = [col for col in equipment_df if group_key in col.lower()]\n",
    "            \n",
    "        data_dict = dict()\n",
    "        for idx in range(max_line_types): \n",
    "            data_dict[str(idx)] = dict()\n",
    "            for dKey in storage_data_keys:\n",
    "                data_dict[str(idx)][dKey] = [None for k in range(equipment_df.shape[0])]\n",
    "\n",
    "        if 'separated' in group_key:\n",
    "            self.extract_line_config_data_from_separated_cells(equipment_df,\n",
    "                                                               configuration_cols,\n",
    "                                                               data_dict,\n",
    "                                                               pdf_data_keys,\n",
    "                                                               storage_key)\n",
    "        else:\n",
    "            self.extract_line_config_data_from_cells_containing_all_key_value_pairs(equipment_df, \n",
    "                                                                                    configuration_cols[0],\n",
    "                                                                                    data_dict, \n",
    "                                                                                    pdf_data_keys,\n",
    "                                                                                    storage_key,)\n",
    "           \n",
    "    def get_exhibit_name(self):\n",
    "        for text_container in self.text_containers[0]:\n",
    "            text = text_container.get_text()\n",
    "            if 'exhibit' in text.lower():\n",
    "                pattern = regex.compile(r'^\\s+')\n",
    "                exhibit = pattern.sub('', text.lower().replace('exhibit', '').replace('\\n', ''))\n",
    "                self.exhibit = exhibit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ocr_pdf_path  = Path('amendments/New_Exhibit_Redacted_docTR.pdf')\n",
    "new_orig_pdf_path = Path('amendments/New_Exhibit_Redacted.pdf')\n",
    "old_ocr_pdf_path  = Path('amendments/Old_Exhibit_Redacted_docTR.pdf')\n",
    "old_orig_pdf_path = Path('amendments/Old_Exhibit_Redacted.pdf')\n",
    "\n",
    "config_path = Path(r'C:\\Users\\Dalton\\Documents\\personal_records\\apex_consulting\\materials_and_amendments_OCR\\configs\\atc_extra_info_config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "storing text from OCR on page 0:\n",
      "\"exhibit a-4 \"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"- e \"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"total lease area sq.ft: \"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"n/a \"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"requirements \"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"grsopuranecqdeu irements\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"tolteaaalsr seqe2a. 1f 6tp:. 0ri0cm oanlrtyeiag aursleoe1a: u2 s.0 w0'1 :8 .0h01:'0 .s0q0.2'f 1t6: .00\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"copnacdre te 10.00'1 6.00n' /a 160.00\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"ouptrsilimdeaeaa rrseyea n /a n/a n/asq .nf/ta:\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"bapcokrwueepqr u irements\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"genne/raat or:f tueasln(i gzknea l/)a: f tueynlp /ea: ftueaslne k(trb aandci/kua s\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"utrielqituyi rements\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"popwroebvruy icdt:i eloiddtmy i preacnty\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"telconlln/ate rconnect:\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"tra&nr semcspeietivcteeifrri :c ations\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"tynp/ea: qunan/atit y:t pxo(iww neart/t as) : eprop(ww neart/t as) :\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"equspipemciefnicta tions\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"type gps panepla netlt a rru/rrrrhu /\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"manufagcteunreerrir c fs cellmarxf s ericsseonri css\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"m#o del gpsa pax423v0-c uam-a a24-ab t/6m521r19/a04ed04b0id7o7-86- 11 r crwu\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"d hxim we xn d1si2 o\"nxs9 9\"6x'x62\"8 41\"x.18\".x587\".16 .x702\" x\"'.x6 114\" x5 1.8 \"3 .22\"0xx1.7 23.\"4.2 \"\"\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"w(eiibgsh.)t 10.0 101.4 35.0 8.4 60.0 52.9\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"locatiogn rountdo wert owert owert owert owe\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"rcaedan gtelrn /a 180.0'1 80.0'1 80.0'1 80.0'1 80.0\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"thipe ightn /a 184.0'1 83.4'1 80.4'1 80.6'1 80.8\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"bhaseei ghtn ia 176.0'1 76.6'1 79.6'1 79.4'1 79.2\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"mtoyupnet n/a saidrem saidrem saidrem saidrem saidrem.\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"quantity1 3 6 3 3 1\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"ra az dimo iafu t it ohnnsi/ dai 6r.0 /1806/03/0800 /6300/01 806/03/0108 0/6300 0\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"aq zup iae mnr t u. thn/s/aec t1o/r1 /1 2/2/2 1/1/1 1/1/1 1\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"utx nf i/r tre sq xu enn/cay mhz mhz n/a n/a mhz\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"tfxrie quennc/ay 668-61 289 183 5 0 5- ,11 79n34/55a-,2 1 1 7n4 45/0a- 2 1 14 75 4- 02\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"rfxre quennciya 622-61 148 725 5 0 5- ,21 18n36/55a-,1 2 7 1n4 45/0a- 1 7 24 15 4- 01\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"u frsu ei qnn ugli e c nen cn ios ee sd ? no no no no no\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"angteaninn an /a 13.2/11381..8163.9 /7 ./2 12 n/a n/a\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"t#oolt fa iln esn ia 3 6 1 3 2\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"n/a q3ty : q6ty : q1ty : q3ty : n/a\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"tycpoea:x t ycpoea:x t yfpibee:t r/ychpoyeab:x ri d\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"indlivinideu al dia1mc/2eod\"ta eixar15: m /8ed\"te iar15:m /8ed\"te iar1:mc/ 4eo\"ta exr:\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"configuratiaonz im1u/c1th/o1/as xe (c1to.6r:3f '-iab4e1zri.m 31mu/1tmh/1/)s , ect\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"azim2u/a2th/z2/ism 1eu/c0tth/o0/rs : ector:\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"n/a n/a n/a n/a n/a q1t y:\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"ty2cp\"o en: d\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"containi\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"-\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"azim1u t\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"conduit\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"configuration q1t y:\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"ty2cp\"o en: d\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"containi\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"-\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"azim1u t\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"conduit\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"configuration\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"tfxrie quennc/ay 668-628185 5,17n3/5a-1 7n4/0a 2 1 14 75 4- 02\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"1850-1865,1745- 1745-1\"\n",
      "page = 0, ypos=0.0, type=<class 'pdfminer.layout.LTFigure'>\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"9.1\"x9.2'x3.9\" \"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"equspipemciefnicta tions\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"type rru/rdrishh -dhips hr-hadpi o/roaddiuo/ doidsuh\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"manufaecrtiucrsescro onm mcsocmopmec sceorapgeco ne ragcoonm m\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"m#o del rru2u2s x6u-6swx 10r-f11uw-dr fu-sdh px\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"hd xim we xn2ds0x1i .o 23x6n\".2. s 96 \"\".x 62 .3x42' .33' 21'0 'x-9'x.1- \"x99..21'\"xx39.49.2.x\"2'x x3 3' .\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"w(eiibgsh.)t 52.9 198.0 579.8 14.3 14.3 70.5\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"locatiotn owert owert owert owert owert owe\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"rcaedan gtelr1 80.0'1 55.0'1 55.0'1 55.0'1 55.0'1 25.0\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"thipeli ght1 80.8'1 158' .1 160.0'1 55.4'1 55.4'1 27.1\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"bhaseei gh1t 79.2'1 51.9'1 50.0'1 54.6'1 54.6'1 22.9\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"mtoyupnte saidrem p moleo upnmto leo upnmto leo upnmto leo upnmto leo u\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"quantity2 1 1 4 2 1\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"a raz dimo iafu t it o1h n8s/ 0d/3ir02.0 9 2.151 84.142 92.151 84.142 92.1\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"aq zup iae mnr t u. th1//s1e cto1r 1 4 2 1\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"t ux nf i/r tre sqx uime nhcyz ghz ghz n/a n/a ghz\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"tfxrie qu2e1 1n4 7c5 4y- 0 2 165 5,171315 - n/a n/a 6\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"rfxre qu1e7 2n4 1c5 4y- 0 1 765 5,2113 5- n/a n/a 6\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"u frsu ei qnn ugli e c nencn isoee sd ? no no no no no\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"angteaninna n /a3 8.3/38n.8//a3 9.n3 /a n/a 35db.5i\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"to#otl fa iln es3 n/a n/a 8 4 n/a\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"q3ty :: nia n/a q4ty : q2ty : n/a\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"tyhplaeri:nd e tycpocen:a ttrboyclelp o cen:at rbolel\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"dia1mh/8ea\"tr edr : dia0m.(37e1d.t8\"ei ar0:m. (37e1.t8\"e r:\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"line mcma)b lme cma)b le\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"azim2u/1th /sector: azim4u athz/ism2eu cttho/rs: ect\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"indlivinideu al\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"configuration\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"q4ty : q2ty :\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"tyfpibee: tr/yhfpiybebe: rri/dh ybri\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"dia0m.(14e9d.t8\"ei ar0:m. (14e9.t8\"e r:\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"mfmib)e rm fmib)e r\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"azim4u athz/ism2eu cttho/rs: ect\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"conduni/ta n/a n/a n/a n/a n/a\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"conduni/ta n/a n/a n/a n/a n/a\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"configuration\"\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"n/a  n/a  n/a \"\n",
      "page = 1, ypos=0.0, type=<class 'pdfminer.layout.LTFigure'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Bounding box (0, 35.24400000000003, 293.76, 710.5299999999996) is not fully within parent page bounding box (0, 0.0, 293.76, 380.16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m new_exhibit\u001b[38;5;241m.\u001b[39mget_text_lines_from_original()\n\u001b[0;32m      3\u001b[0m new_exhibit\u001b[38;5;241m.\u001b[39mget_text_lines_from_ocr()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mnew_exhibit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morganize_text_lines_by_row_and_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m new_exhibit\u001b[38;5;241m.\u001b[39mget_section_bounds()\n\u001b[0;32m      6\u001b[0m new_exhibit\u001b[38;5;241m.\u001b[39mfill_implicit_keys(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mground space requirements\u001b[39m\u001b[38;5;124m'\u001b[39m, left_mult\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, right_mult\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 211\u001b[0m, in \u001b[0;36mpdf_data.organize_text_lines_by_row_and_column\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    209\u001b[0m orig_pdf \u001b[38;5;241m=\u001b[39m pdfplumber\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_filepath) \n\u001b[0;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morganize_single_lines(merge_sets, ocr_pdf, orig_pdf)\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_merge_sets\u001b[49m\u001b[43m   \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerge_sets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mocr_pdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_pdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 189\u001b[0m, in \u001b[0;36mpdf_data.combine_merge_sets\u001b[1;34m(self, merge_sets, ocr_pdf, orig_pdf)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     page \u001b[38;5;241m=\u001b[39m orig_pdf\u001b[38;5;241m.\u001b[39mpages[partial_df\u001b[38;5;241m.\u001b[39mloc[merge_set[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m--> 189\u001b[0m words_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_words_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_top\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_bottom\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m col_phrases \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midentify_columns_from_words_df(words_df)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# replace first line in merge set with merged text and position info, then store indices of \u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# remaining merge set to drop at end of combine method\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 118\u001b[0m, in \u001b[0;36mpdf_data.get_words_df\u001b[1;34m(self, page, y_top, y_bottom)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_words_df\u001b[39m(\u001b[38;5;28mself\u001b[39m, page, y_top, y_bottom):\n\u001b[1;32m--> 118\u001b[0m     page_crop \u001b[38;5;241m=\u001b[39m \u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithin_bbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_top\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_bottom\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m    121\u001b[0m     words \u001b[38;5;241m=\u001b[39m page_crop\u001b[38;5;241m.\u001b[39mextract_words()  \n\u001b[0;32m    122\u001b[0m     words_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(text\u001b[38;5;241m=\u001b[39m[], left\u001b[38;5;241m=\u001b[39m[], right\u001b[38;5;241m=\u001b[39m[], top\u001b[38;5;241m=\u001b[39m[], bottom\u001b[38;5;241m=\u001b[39m[])\n",
      "File \u001b[1;32mc:\\Users\\Dalton\\Documents\\personal_records\\apex_consulting\\doctr_ocr\\.conda\\Lib\\site-packages\\pdfplumber\\page.py:543\u001b[0m, in \u001b[0;36mPage.within_bbox\u001b[1;34m(self, bbox, relative, strict)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwithin_bbox\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m, bbox: T_bbox, relative: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, strict: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    539\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCroppedPage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    540\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;124;03m    Same as .crop, except only includes objects fully within the bbox\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCroppedPage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithin_bbox\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dalton\\Documents\\personal_records\\apex_consulting\\doctr_ocr\\.conda\\Lib\\site-packages\\pdfplumber\\page.py:677\u001b[0m, in \u001b[0;36mCroppedPage.__init__\u001b[1;34m(self, parent_page, crop_bbox, crop_fn, relative, strict)\u001b[0m\n\u001b[0;32m    674\u001b[0m     crop_bbox \u001b[38;5;241m=\u001b[39m (x0 \u001b[38;5;241m+\u001b[39m o_x0, top \u001b[38;5;241m+\u001b[39m o_top, x1 \u001b[38;5;241m+\u001b[39m o_x0, bottom \u001b[38;5;241m+\u001b[39m o_top)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strict:\n\u001b[1;32m--> 677\u001b[0m     \u001b[43mtest_proposed_bbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrop_bbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_page\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_crop_fn\u001b[39m(objs: T_obj_list) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T_obj_list:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m crop_fn(objs, crop_bbox)\n",
      "File \u001b[1;32mc:\\Users\\Dalton\\Documents\\personal_records\\apex_consulting\\doctr_ocr\\.conda\\Lib\\site-packages\\pdfplumber\\page.py:656\u001b[0m, in \u001b[0;36mtest_proposed_bbox\u001b[1;34m(bbox, parent_bbox)\u001b[0m\n\u001b[0;32m    654\u001b[0m overlap_area \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcalculate_area(overlap)\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overlap_area \u001b[38;5;241m<\u001b[39m bbox_area:\n\u001b[1;32m--> 656\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    657\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBounding box \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbbox\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not fully within \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    658\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparent page bounding box \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent_bbox\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    659\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Bounding box (0, 35.24400000000003, 293.76, 710.5299999999996) is not fully within parent page bounding box (0, 0.0, 293.76, 380.16)"
     ]
    }
   ],
   "source": [
    "new_exhibit = ATC_amendment(new_orig_pdf_path, new_ocr_pdf_path, config_path, ':')\n",
    "new_exhibit.get_text_lines_from_original()\n",
    "new_exhibit.get_text_lines_from_ocr()\n",
    "new_exhibit.organize_text_lines_by_row_and_column()\n",
    "new_exhibit.get_section_bounds()\n",
    "new_exhibit.fill_implicit_keys('ground space requirements', left_mult=2, right_mult=2)\n",
    "new_exhibit.extract_table_data()\n",
    "new_exhibit.extract_text_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qty: 3\n",
      "Type: Coax\n",
      "Diameter: 1/2\" Coax\n",
      "Azimuth/Sector: 1/1/1\n",
      "Qty: 6\n",
      "Type: Coax\n",
      "Diameter: 1 5/8\"Coax\n",
      "Azimuth/Sector: 2/2/2\n",
      "Qty: 1\n",
      "Type: Fiber/Hybrid\n",
      "Diameter: 1 5/8\"(1.63\"-41.3mm) Fiber\n",
      "Azimuth/Sector: 1/0/0\n",
      "Qty: 3\n",
      "Type: Coax\n",
      "Diameter: 1/4\" Coax\n",
      "Azimuth/Sector: 1/1/1\n",
      "Qty: 3\n",
      "Type: Hard Line\n",
      "Diameter: 1/8\" HardLine\n",
      "Azimuth/Sector: 2/1\n",
      "Qty: 4\n",
      "Qty: 4\n",
      "Type: Control Cable\n",
      "Type: Control Cable\n",
      "Diameter: 0.31\" (7.8mm) Cable\n",
      "Diameter: 0.31\" (7.8mm) Cable\n",
      "Azimuth/Sector: 4\n",
      "Azimuth/Sector: 4\n",
      "Qty: 2\n",
      "Qty: 2\n",
      "Type: Control Cable\n",
      "Type: Control Cable\n",
      "Diameter: 0.31\" (7.8mm) Cable\n",
      "Diameter: 0.31\" (7.8mm) Cable\n",
      "Azimuth/Sector: 2\n",
      "Azimuth/Sector: 2\n",
      "Qty: 1\n",
      "Qty: 1\n",
      "Type: 2\" conduit\n",
      "Type: 2\" conduit\n",
      "containing:-;\n",
      "containing:-;\n",
      "Azimuth/Sector: 1\n",
      "Azimuth/Sector: 1\n"
     ]
    }
   ],
   "source": [
    "new_exhibit.align_line_configuration_data(group_key = 'line configuration'   , max_line_types=2)\n",
    "new_exhibit.align_line_configuration_data(group_key = 'conduit configuration', max_line_types=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model #</th>\n",
       "      <th>Dimensions HxWxD</th>\n",
       "      <th>Weight (lbs.)</th>\n",
       "      <th>Location</th>\n",
       "      <th>RAD Center AGL</th>\n",
       "      <th>Tip Height</th>\n",
       "      <th>Base Height</th>\n",
       "      <th>Mount Type</th>\n",
       "      <th>...</th>\n",
       "      <th>line_config_1_Diameter</th>\n",
       "      <th>line_config_1_Azimuth/Sector</th>\n",
       "      <th>conduit_config_0_Qty</th>\n",
       "      <th>conduit_config_0_Type</th>\n",
       "      <th>conduit_config_0_containing</th>\n",
       "      <th>conduit_config_0_Azimuth/Sector</th>\n",
       "      <th>conduit_config_1_Qty</th>\n",
       "      <th>conduit_config_1_Type</th>\n",
       "      <th>conduit_config_1_containing</th>\n",
       "      <th>conduit_config_1_Azimuth/Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPS</td>\n",
       "      <td>Generic</td>\n",
       "      <td>GPS</td>\n",
       "      <td>12\" x 9\" x 6\"</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Ground</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PANEL</td>\n",
       "      <td>RFS</td>\n",
       "      <td>APXVAA24_43-U-\\nA20</td>\n",
       "      <td>96\" x 24\" x 8.5\"</td>\n",
       "      <td>101.4</td>\n",
       "      <td>Tower</td>\n",
       "      <td>180.0'</td>\n",
       "      <td>184.0'</td>\n",
       "      <td>176.0'</td>\n",
       "      <td>Side Arm</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PANEL</td>\n",
       "      <td>CellMax</td>\n",
       "      <td>CMA-B/6521/E0-6</td>\n",
       "      <td>81.1\" x 7.7\" x 4.8\"</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Tower</td>\n",
       "      <td>180.0'</td>\n",
       "      <td>183.4'</td>\n",
       "      <td>176.6'</td>\n",
       "      <td>Side Arm</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTA</td>\n",
       "      <td>RFS</td>\n",
       "      <td>ATM1900D-1CWA</td>\n",
       "      <td>8.6\" x 10\" x 2.6\"</td>\n",
       "      <td>8.4</td>\n",
       "      <td>Tower</td>\n",
       "      <td>180.0'</td>\n",
       "      <td>180.4'</td>\n",
       "      <td>179.6'</td>\n",
       "      <td>Side Arm</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RRU/RRH</td>\n",
       "      <td>Ericsson</td>\n",
       "      <td>Radio 4478 B71</td>\n",
       "      <td>15\" x 13.2\" x 7.4\"</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Tower</td>\n",
       "      <td>180.0'</td>\n",
       "      <td>180.6'</td>\n",
       "      <td>179.4'</td>\n",
       "      <td>Side Arm</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RRU/RRH</td>\n",
       "      <td>Ericsson</td>\n",
       "      <td>RRU22</td>\n",
       "      <td>20.2\" x 13.2\" x 6.9\"</td>\n",
       "      <td>52.9</td>\n",
       "      <td>Tower</td>\n",
       "      <td>180.0'</td>\n",
       "      <td>180.8'</td>\n",
       "      <td>179.2'</td>\n",
       "      <td>Side Arm</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2\" conduit</td>\n",
       "      <td>-;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2\" conduit</td>\n",
       "      <td>-;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RRU/RRH</td>\n",
       "      <td>Ericsson</td>\n",
       "      <td>RRU22</td>\n",
       "      <td>20.2\" x 13.2\" x 6.9\"</td>\n",
       "      <td>52.9</td>\n",
       "      <td>Tower</td>\n",
       "      <td>180.0'</td>\n",
       "      <td>180.8'</td>\n",
       "      <td>179.2'</td>\n",
       "      <td>Side Arm</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DISH-HP</td>\n",
       "      <td>Commscope</td>\n",
       "      <td>USX6-6W</td>\n",
       "      <td>6.23' x 6.23' x 4.32'</td>\n",
       "      <td>198.0</td>\n",
       "      <td>Tower</td>\n",
       "      <td>155.0'</td>\n",
       "      <td>158.1'</td>\n",
       "      <td>151.9'</td>\n",
       "      <td>Pole Mount</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DISH-HP</td>\n",
       "      <td>Commscope</td>\n",
       "      <td>USX10-11W</td>\n",
       "      <td>10' x -' x -'</td>\n",
       "      <td>579.8</td>\n",
       "      <td>Tower</td>\n",
       "      <td>155.0'</td>\n",
       "      <td>160.0'</td>\n",
       "      <td>150.0'</td>\n",
       "      <td>Pole Mount</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Radio/ODU</td>\n",
       "      <td>Ceragon</td>\n",
       "      <td>RFU-D</td>\n",
       "      <td>9.1\" x 9.2\" x 3.9\"</td>\n",
       "      <td>14.3</td>\n",
       "      <td>Tower</td>\n",
       "      <td>155.0'</td>\n",
       "      <td>155.4'</td>\n",
       "      <td>154.6'</td>\n",
       "      <td>Pole Mount</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31\" (7.8mm) Cable</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Radio/ODU</td>\n",
       "      <td>Ceragon</td>\n",
       "      <td>RFU-D</td>\n",
       "      <td>9.1\" x 9.2\" x 3.9\"</td>\n",
       "      <td>14.3</td>\n",
       "      <td>Tower</td>\n",
       "      <td>155.0'</td>\n",
       "      <td>155.4'</td>\n",
       "      <td>154.6'</td>\n",
       "      <td>Pole Mount</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31\" (7.8mm) Cable</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DISH-HP</td>\n",
       "      <td>Commscope</td>\n",
       "      <td>SHPX4-6W</td>\n",
       "      <td>4.23' x -' x -'</td>\n",
       "      <td>70.5</td>\n",
       "      <td>Tower</td>\n",
       "      <td>125.0'</td>\n",
       "      <td>127.1'</td>\n",
       "      <td>122.9'</td>\n",
       "      <td>Pole Mount</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows  37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Type Manufacturer              Model #       Dimensions HxWxD  \\\n",
       "0         GPS      Generic                  GPS          12\" x 9\" x 6\"   \n",
       "1       PANEL          RFS  APXVAA24_43-U-\\nA20       96\" x 24\" x 8.5\"   \n",
       "2       PANEL      CellMax      CMA-B/6521/E0-6    81.1\" x 7.7\" x 4.8\"   \n",
       "3         TTA          RFS        ATM1900D-1CWA      8.6\" x 10\" x 2.6\"   \n",
       "4     RRU/RRH     Ericsson       Radio 4478 B71     15\" x 13.2\" x 7.4\"   \n",
       "5     RRU/RRH     Ericsson                RRU22   20.2\" x 13.2\" x 6.9\"   \n",
       "6     RRU/RRH     Ericsson                RRU22   20.2\" x 13.2\" x 6.9\"   \n",
       "7     DISH-HP    Commscope              USX6-6W  6.23' x 6.23' x 4.32'   \n",
       "8     DISH-HP    Commscope            USX10-11W          10' x -' x -'   \n",
       "9   Radio/ODU      Ceragon                RFU-D     9.1\" x 9.2\" x 3.9\"   \n",
       "10  Radio/ODU      Ceragon                RFU-D     9.1\" x 9.2\" x 3.9\"   \n",
       "11    DISH-HP    Commscope             SHPX4-6W        4.23' x -' x -'   \n",
       "\n",
       "   Weight (lbs.) Location RAD Center AGL Tip Height Base Height  Mount Type  \\\n",
       "0           10.0   Ground            N/A        N/A         N/A         N/A   \n",
       "1          101.4    Tower         180.0'     184.0'      176.0'    Side Arm   \n",
       "2           35.0    Tower         180.0'     183.4'      176.6'    Side Arm   \n",
       "3            8.4    Tower         180.0'     180.4'      179.6'    Side Arm   \n",
       "4           60.0    Tower         180.0'     180.6'      179.4'    Side Arm   \n",
       "5           52.9    Tower         180.0'     180.8'      179.2'    Side Arm   \n",
       "6           52.9    Tower         180.0'     180.8'      179.2'    Side Arm   \n",
       "7          198.0    Tower         155.0'     158.1'      151.9'  Pole Mount   \n",
       "8          579.8    Tower         155.0'     160.0'      150.0'  Pole Mount   \n",
       "9           14.3    Tower         155.0'     155.4'      154.6'  Pole Mount   \n",
       "10          14.3    Tower         155.0'     155.4'      154.6'  Pole Mount   \n",
       "11          70.5    Tower         125.0'     127.1'      122.9'  Pole Mount   \n",
       "\n",
       "    ... line_config_1_Diameter line_config_1_Azimuth/Sector  \\\n",
       "0   ...                   None                         None   \n",
       "1   ...                   None                         None   \n",
       "2   ...                   None                         None   \n",
       "3   ...                   None                         None   \n",
       "4   ...                   None                         None   \n",
       "5   ...                   None                         None   \n",
       "6   ...                   None                         None   \n",
       "7   ...                   None                         None   \n",
       "8   ...                   None                         None   \n",
       "9   ...    0.31\" (7.8mm) Cable                            4   \n",
       "10  ...    0.31\" (7.8mm) Cable                            2   \n",
       "11  ...                   None                         None   \n",
       "\n",
       "   conduit_config_0_Qty conduit_config_0_Type conduit_config_0_containing  \\\n",
       "0                  None                  None                        None   \n",
       "1                  None                  None                        None   \n",
       "2                  None                  None                        None   \n",
       "3                  None                  None                        None   \n",
       "4                  None                  None                        None   \n",
       "5                     1            2\" conduit                          -;   \n",
       "6                  None                  None                        None   \n",
       "7                  None                  None                        None   \n",
       "8                  None                  None                        None   \n",
       "9                  None                  None                        None   \n",
       "10                 None                  None                        None   \n",
       "11                 None                  None                        None   \n",
       "\n",
       "   conduit_config_0_Azimuth/Sector conduit_config_1_Qty conduit_config_1_Type  \\\n",
       "0                             None                 None                  None   \n",
       "1                             None                 None                  None   \n",
       "2                             None                 None                  None   \n",
       "3                             None                 None                  None   \n",
       "4                             None                 None                  None   \n",
       "5                                1                    1            2\" conduit   \n",
       "6                             None                 None                  None   \n",
       "7                             None                 None                  None   \n",
       "8                             None                 None                  None   \n",
       "9                             None                 None                  None   \n",
       "10                            None                 None                  None   \n",
       "11                            None                 None                  None   \n",
       "\n",
       "   conduit_config_1_containing conduit_config_1_Azimuth/Sector  \n",
       "0                         None                            None  \n",
       "1                         None                            None  \n",
       "2                         None                            None  \n",
       "3                         None                            None  \n",
       "4                         None                            None  \n",
       "5                           -;                               1  \n",
       "6                         None                            None  \n",
       "7                         None                            None  \n",
       "8                         None                            None  \n",
       "9                         None                            None  \n",
       "10                        None                            None  \n",
       "11                        None                            None  \n",
       "\n",
       "[12 rows x 37 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_exhibit.sections['ground space requirements']['data']\n",
    "new_exhibit.sections['backup power requirements']['data']\n",
    "new_exhibit.sections['utility requirements']['data']\n",
    "new_exhibit.sections['transmitter & receiver specifications']['data']\n",
    "new_exhibit.sections['equipment specifications']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "storing text from OCR on page 0:\n",
      "\"exhibit a-3\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"total lease area sq.ft:21600 primary contiguous lease area l:1200 w:1800 h:1000 sq.ft: 216.00)\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"ground space requirements\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"concrete pad 1000 16.00\" nia 160.00]\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"outside primary lease area nia nia nia sq. ft: n/a|\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"backup power requirements\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"generator: nia capacity(kw): n/a fuel tank size(gal): n/a fuel type: nia fuel tank setback{radiu:\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"utility requirements\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"power provided by: utiity company direct\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"telco/lnterconnect:\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"ua\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"transmitter & receiver specifications\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"type: n/a quantity: nia tx power(watts): nia erp(watts): n/a\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"equipment specifications\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"type panel panel tta rrurrh rrurrh rrurrh\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"manufacturer cellmax rfs rfs ericsson ericsson ericsson\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"model # cmabigs21/e06 | apxvaa24_43-u-a20| atm1900d-1cwa rruz2 rru22 radio 4478 b71\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"dimensions hxwxd | 81.1'x7.7'x48 | 96'x24'x85 | 86x10x26 | 202x132 x69\" | 02x 132x689\" | 16x 132 x74\"\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"[weight(ibs.) 350 1014 84 529 529 600\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"location tower, tower, tower tower tower tower\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"rad center agl 180.0\" 180.0\" 180.0 180.0\" 180.0\" 180.0\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"equipment tip 1834 1840 1804 1808 1808 180.6\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"equipment base 1766 1760 1796 1792 1792 179.4\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"eight\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"mount type side am side am side am side am side am side am\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"quantity 6 3 3 1 2 3\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"rzimuths/dir. of 60/80/300 6011807300 6011807300 60 180/300 6011801300\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"quant. per\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"quant. per cor na 111 nn 1 n nn\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"(rx frequency mhz mhz na mhz mhz na\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"nits\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"tx frequency 215517351740 668-638 nia 1740 1740 nia\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"1930-1945.2145- 21452155, 1736 | 2145-2155,1736-\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"rx frequency 175521352140 622642 na 2140 2140 na\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"using unlicensed no no no no o no\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"1850-1865,1745- 74517552135 | 1745-1756.2135-\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"frequencies?\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"equipment gain 18.31 18.7/192 132/136 2 na na na\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"total # of lines 6 3 1 2 3 3\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"line quant. per\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"fliinnee qquuaanntt. ppeerr na nn 11000 2 n nn\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"line type coax coax fiberfhybrid conduit hard line coax\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"line diameter size 15/8\" coax 112\" coax 15/et(les aiim) 2 conduit 1/8\" hard line 114 coax\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"line configuration na na na na na na\"\n",
      "page = 0, ypos=7.38e-07, type=<class 'pdfminer.layout.LTFigure'>\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"equipment specifications\"\n",
      "page = 1, ypos=-5.348e-06, type=<class 'pdfminer.layout.LTFigure'>\n"
     ]
    }
   ],
   "source": [
    "old_exhibit = ATC_amendment(old_orig_pdf_path, old_ocr_pdf_path, config_path, ':')\n",
    "old_exhibit.get_text_lines_from_original()\n",
    "old_exhibit.get_text_lines_from_ocr()\n",
    "old_exhibit.organize_text_lines_by_row_and_column()\n",
    "old_exhibit.get_section_bounds()\n",
    "old_exhibit.fill_implicit_keys('ground space requirements', left_mult=2, right_mult=2)\n",
    "old_exhibit.extract_table_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total lease area sq.ft: 21600\n",
      "primary contiguous lease area - l: 1200\n",
      "primary contiguous lease area - w: 1800\n",
      "primary contiguous lease area - h: 1000\n",
      "primary contiguous lease area - sq.ft: 216.00)\n",
      "concrete pad - l: 1000\n",
      "concrete pad - w: 16.00\"\n",
      "concrete pad - h: nia\n",
      "concrete pad - sq.ft: 160.00]\n",
      "outside primary lease area - l: nia\n",
      "outside primary lease area - w: nia\n",
      "outside primary lease area - h: nia\n",
      "outside primary lease area - sq. ft: n/a\n",
      "generator: nia\n",
      "capacity(kw): n/a\n",
      "fuel tank size(gal): n/a\n",
      "fuel type: nia\n",
      "fuel tank setback{radiu: None\n",
      "power provided by: utiity company direct\n",
      "telco/lnterconnect: ua\n",
      "telco/lnterconnect: ua\n",
      "type: n/a\n",
      "quantity: nia\n",
      "tx power(watts): nia\n",
      "erp(watts): n/a\n",
      "type Line Type\n",
      "manufacturer Quant. Per Azimuth/Sector\n",
      "model # Model #\n",
      "dimensions hxwxd Dimensions HxWxD\n",
      "[weight(ibs.) Using Unlicensed Frequencies?\n",
      "location Total # of Lines\n",
      "rad center agl RAD Center AGL\n",
      "equipment tip Equipment Tip Height\n",
      "equipment base eight Equipment Base Height\n",
      "mount type Mount Type\n",
      "quantity Line Quant. Per Azimuth/Sector\n",
      "rzimuths/dir. of Azimuths/Dir. of Radiation\n",
      "qquuaanntt.. ppeerr cor Manufacturer\n",
      "(rx frequency nits TX/RX Frequency Units\n",
      "tx frequency Equipment Gain\n",
      "rx frequency Line Configuration\n",
      "using unlicensed Weight(lbs.)\n",
      "frequencies? TX Frequency\n",
      "equipment gain Line Diameter Size\n",
      "total # of lines Location\n",
      "fliinnee qquuaanntt. ppeerr Quantity\n",
      "line type Type\n",
      "line diameter size RX Frequency\n",
      "line configuration \n",
      "\n",
      "\"TX Frequency\" contained the wrong number of columns in the line.\n",
      "\n",
      "\"RX Frequency\" contained the wrong number of columns in the line.\n"
     ]
    }
   ],
   "source": [
    "old_exhibit.extract_text_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1     0\n",
      "2     4\n",
      "3     0\n",
      "4     1\n",
      "5     0\n",
      "6     6\n",
      "7     3\n",
      "8     1\n",
      "9     2\n",
      "10    3\n",
      "11    3\n",
      "Name: Total # of Lines, dtype: object\n",
      "0         Coax\n",
      "1          N/A\n",
      "2     Multiple\n",
      "3          N/A\n",
      "4         Coax\n",
      "5          N/A\n",
      "6           na\n",
      "7           nn\n",
      "8        11000\n",
      "9            2\n",
      "10           n\n",
      "11          nn\n",
      "Name: Line Type, dtype: object\n",
      "0      0.29\" (7.2mm) RG-8\n",
      "1                     N/A\n",
      "2     See Config. Summary\n",
      "3                     N/A\n",
      "4      0.29\" (7.2mm) RG-8\n",
      "5                     N/A\n",
      "6          18.31 18.7/192\n",
      "7                 132/136\n",
      "8                       2\n",
      "9                      na\n",
      "10                     na\n",
      "11                     na\n",
      "Name: Line Diameter Size, dtype: object\n",
      "0                       1\n",
      "1                     N/A\n",
      "2     See Config. Summary\n",
      "3                     N/A\n",
      "4                       1\n",
      "5                     N/A\n",
      "6       wrong_num_columns\n",
      "7       wrong_num_columns\n",
      "8       wrong_num_columns\n",
      "9       wrong_num_columns\n",
      "10      wrong_num_columns\n",
      "11      wrong_num_columns\n",
      "Name: Line Quant. Per Azimuth/Sector, dtype: object\n",
      "0                                                   N/A\n",
      "1                                                   N/A\n",
      "2     2 - Control Cable;\\n0.31\" (7.8mm) Cable;\\n2\\n2...\n",
      "3                                                   N/A\n",
      "4                                                   N/A\n",
      "5                                                   N/A\n",
      "6                                                  coax\n",
      "7                                                  coax\n",
      "8                                          fiberfhybrid\n",
      "9                                              conduit\n",
      "10                                            hard line\n",
      "11                                                 coax\n",
      "Name: Line Configuration, dtype: object\n",
      "Total # of Lines                                   1\n",
      "Line Type                                       Coax\n",
      "Line Diameter Size                0.29\" (7.2mm) RG-8\n",
      "Line Quant. Per Azimuth/Sector                     1\n",
      "Line Configuration                               N/A\n",
      "Name: 0, dtype: object\n",
      "Total # of Lines                    0\n",
      "Line Type                         N/A\n",
      "Line Diameter Size                N/A\n",
      "Line Quant. Per Azimuth/Sector    N/A\n",
      "Line Configuration                N/A\n",
      "Name: 1, dtype: object\n",
      "Total # of Lines                                                                  4\n",
      "Line Type                                                                  Multiple\n",
      "Line Diameter Size                                              See Config. Summary\n",
      "Line Quant. Per Azimuth/Sector                                  See Config. Summary\n",
      "Line Configuration                2 - Control Cable;\\n0.31\" (7.8mm) Cable;\\n2\\n2...\n",
      "Name: 2, dtype: object\n",
      "Total # of Lines                    0\n",
      "Line Type                         N/A\n",
      "Line Diameter Size                N/A\n",
      "Line Quant. Per Azimuth/Sector    N/A\n",
      "Line Configuration                N/A\n",
      "Name: 3, dtype: object\n",
      "Total # of Lines                                   1\n",
      "Line Type                                       Coax\n",
      "Line Diameter Size                0.29\" (7.2mm) RG-8\n",
      "Line Quant. Per Azimuth/Sector                     1\n",
      "Line Configuration                               N/A\n",
      "Name: 4, dtype: object\n",
      "Total # of Lines                    0\n",
      "Line Type                         N/A\n",
      "Line Diameter Size                N/A\n",
      "Line Quant. Per Azimuth/Sector    N/A\n",
      "Line Configuration                N/A\n",
      "Name: 5, dtype: object\n",
      "Total # of Lines                                  6\n",
      "Line Type                                        na\n",
      "Line Diameter Size                   18.31 18.7/192\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                             coax\n",
      "Name: 6, dtype: object\n",
      "Total # of Lines                                  3\n",
      "Line Type                                        nn\n",
      "Line Diameter Size                          132/136\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                             coax\n",
      "Name: 7, dtype: object\n",
      "Total # of Lines                                  1\n",
      "Line Type                                     11000\n",
      "Line Diameter Size                                2\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                     fiberfhybrid\n",
      "Name: 8, dtype: object\n",
      "Total # of Lines                                  2\n",
      "Line Type                                         2\n",
      "Line Diameter Size                               na\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                         conduit\n",
      "Name: 9, dtype: object\n",
      "Total # of Lines                                  3\n",
      "Line Type                                         n\n",
      "Line Diameter Size                               na\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                        hard line\n",
      "Name: 10, dtype: object\n",
      "Total # of Lines                                  3\n",
      "Line Type                                        nn\n",
      "Line Diameter Size                               na\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                             coax\n",
      "Name: 11, dtype: object\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "3\n",
      "nn\n",
      "na\n",
      "wrong_num_columns\n",
      "Qty: 3\n",
      "Type: nn\n",
      "Diameter: na\n",
      "Azimuth/Sector: wrong_num_columns\n",
      "Total # of Lines                                  3\n",
      "Line Type                                        nn\n",
      "Line Diameter Size                               na\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                             coax\n",
      "Name: 11, dtype: object\n",
      "Qty: 3\n",
      "Total # of Lines                                  3\n",
      "Line Type                                        nn\n",
      "Line Diameter Size                               na\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                             coax\n",
      "Name: 11, dtype: object\n",
      "Type: nn\n",
      "Total # of Lines                                  3\n",
      "Line Type                                        nn\n",
      "Line Diameter Size                               na\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                             coax\n",
      "Name: 11, dtype: object\n",
      "Diameter: na\n",
      "Total # of Lines                                  3\n",
      "Line Type                                        nn\n",
      "Line Diameter Size                               na\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                             coax\n",
      "Name: 11, dtype: object\n",
      "Azimuth/Sector: wrong_num_columns\n"
     ]
    }
   ],
   "source": [
    "old_exhibit.align_line_configuration_data(group_key = 'separated configuration', max_line_types=2, type_key = 'line')\n",
    "old_exhibit.align_line_configuration_data(group_key = 'separated configuration', max_line_types=2, type_key = 'conduit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model #</th>\n",
       "      <th>Dimensions HxWxD</th>\n",
       "      <th>Weight(lbs.)</th>\n",
       "      <th>Location</th>\n",
       "      <th>RAD Center AGL</th>\n",
       "      <th>Equipment Tip Height</th>\n",
       "      <th>Equipment Base Height</th>\n",
       "      <th>...</th>\n",
       "      <th>TX/RX Frequency Units</th>\n",
       "      <th>TX Frequency</th>\n",
       "      <th>RX Frequency</th>\n",
       "      <th>Using Unlicensed Frequencies?</th>\n",
       "      <th>Equipment Gain</th>\n",
       "      <th>Total # of Lines</th>\n",
       "      <th>Line Quant. Per Azimuth/Sector</th>\n",
       "      <th>Line Type</th>\n",
       "      <th>Line Diameter Size</th>\n",
       "      <th>Line Configuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>DISH-HP</td>\n",
       "      <td>RFS</td>\n",
       "      <td>SB6-W60BC</td>\n",
       "      <td>6.23' x 6.23' x 2.98'</td>\n",
       "      <td>198.0</td>\n",
       "      <td>Tower</td>\n",
       "      <td>155.0'</td>\n",
       "      <td>158.1'</td>\n",
       "      <td>151.9'</td>\n",
       "      <td>...</td>\n",
       "      <td>MHz</td>\n",
       "      <td>6400</td>\n",
       "      <td>6400</td>\n",
       "      <td>No</td>\n",
       "      <td>35.7/ 36.7/ 37.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Coax</td>\n",
       "      <td>0.29\" (7.2mm) RG-8</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>DISH-HP</td>\n",
       "      <td>Commscope</td>\n",
       "      <td>USX10-11W</td>\n",
       "      <td>10.00' x -' x -'</td>\n",
       "      <td>579.8</td>\n",
       "      <td>Tower</td>\n",
       "      <td>155.0'</td>\n",
       "      <td>160.0'</td>\n",
       "      <td>150.0'</td>\n",
       "      <td>...</td>\n",
       "      <td>GHz</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Radio/ODU</td>\n",
       "      <td>Ceragon</td>\n",
       "      <td>RFU-D</td>\n",
       "      <td>9.1\" x 9.2\" x 3.9\"</td>\n",
       "      <td>14.3</td>\n",
       "      <td>Tower</td>\n",
       "      <td>155.0'</td>\n",
       "      <td>155.4'</td>\n",
       "      <td>154.6'</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>No</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4</td>\n",
       "      <td>See Config. Summary</td>\n",
       "      <td>Multiple</td>\n",
       "      <td>See Config. Summary</td>\n",
       "      <td>2 - Control Cable;\\n0.31\" (7.8mm) Cable;\\n2\\n2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Radio/ODU</td>\n",
       "      <td>Ceragon</td>\n",
       "      <td>FibeAir IP-20E</td>\n",
       "      <td>9.2\" x 9.1\" x 3.9\"</td>\n",
       "      <td>14.3</td>\n",
       "      <td>Tower</td>\n",
       "      <td>155.0'</td>\n",
       "      <td>155.4'</td>\n",
       "      <td>154.6'</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>No</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>DISH-HP</td>\n",
       "      <td>RFS</td>\n",
       "      <td>SB4-W60</td>\n",
       "      <td>4.14' x 4.14' x -'</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Tower</td>\n",
       "      <td>125.0'</td>\n",
       "      <td>127.1'</td>\n",
       "      <td>122.9'</td>\n",
       "      <td>...</td>\n",
       "      <td>MHz</td>\n",
       "      <td>6400</td>\n",
       "      <td>6400</td>\n",
       "      <td>No</td>\n",
       "      <td>32.4 / 32.7 / 33.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Coax</td>\n",
       "      <td>0.29\" (7.2mm) RG-8</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>Radio/ODU</td>\n",
       "      <td>Ceragon</td>\n",
       "      <td>FibeAir IP-20E</td>\n",
       "      <td>9.2\" x 9.1\" x 3.9\"</td>\n",
       "      <td>14.3</td>\n",
       "      <td>Tower</td>\n",
       "      <td>125.0'</td>\n",
       "      <td>125.4'</td>\n",
       "      <td>124.6'</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>No</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>na</td>\n",
       "      <td>panel</td>\n",
       "      <td>cellmax</td>\n",
       "      <td>cmabigs21/e06</td>\n",
       "      <td>81.1'x7.7'x48</td>\n",
       "      <td>350</td>\n",
       "      <td>tower,</td>\n",
       "      <td>180.0\"</td>\n",
       "      <td>na</td>\n",
       "      <td>1766</td>\n",
       "      <td>...</td>\n",
       "      <td>mhz</td>\n",
       "      <td>1930-1945.2145- 215517351740</td>\n",
       "      <td>11875505-12816355,21174450-</td>\n",
       "      <td>no</td>\n",
       "      <td>1834</td>\n",
       "      <td>6</td>\n",
       "      <td>wrong_num_columns</td>\n",
       "      <td>na</td>\n",
       "      <td>18.31 18.7/192</td>\n",
       "      <td>coax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>na</td>\n",
       "      <td>panel</td>\n",
       "      <td>rfs</td>\n",
       "      <td>apxvaa24_43-u-a20</td>\n",
       "      <td>96'x24'x85</td>\n",
       "      <td>1014</td>\n",
       "      <td>tower,</td>\n",
       "      <td>180.0\"</td>\n",
       "      <td>111</td>\n",
       "      <td>1760</td>\n",
       "      <td>...</td>\n",
       "      <td>mhz</td>\n",
       "      <td>668-638</td>\n",
       "      <td>622642</td>\n",
       "      <td>no</td>\n",
       "      <td>1840</td>\n",
       "      <td>3</td>\n",
       "      <td>wrong_num_columns</td>\n",
       "      <td>nn</td>\n",
       "      <td>132/136</td>\n",
       "      <td>coax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>na</td>\n",
       "      <td>tta</td>\n",
       "      <td>rfs</td>\n",
       "      <td>atm1900d-1cwa</td>\n",
       "      <td>86x10x26</td>\n",
       "      <td>84</td>\n",
       "      <td>tower</td>\n",
       "      <td>180.0</td>\n",
       "      <td>nn</td>\n",
       "      <td>1796</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>nia</td>\n",
       "      <td>na</td>\n",
       "      <td>no</td>\n",
       "      <td>1804</td>\n",
       "      <td>1</td>\n",
       "      <td>wrong_num_columns</td>\n",
       "      <td>11000</td>\n",
       "      <td>2</td>\n",
       "      <td>fiberfhybrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>na</td>\n",
       "      <td>rrurrh</td>\n",
       "      <td>ericsson</td>\n",
       "      <td>rruz2</td>\n",
       "      <td>202x132 x69\"</td>\n",
       "      <td>529</td>\n",
       "      <td>tower</td>\n",
       "      <td>180.0\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1792</td>\n",
       "      <td>...</td>\n",
       "      <td>mhz</td>\n",
       "      <td>21452155, 1736 1740</td>\n",
       "      <td>74512715450 2135</td>\n",
       "      <td>no</td>\n",
       "      <td>1808</td>\n",
       "      <td>2</td>\n",
       "      <td>wrong_num_columns</td>\n",
       "      <td>2</td>\n",
       "      <td>na</td>\n",
       "      <td>conduit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>na</td>\n",
       "      <td>rrurrh</td>\n",
       "      <td>ericsson</td>\n",
       "      <td>rru22</td>\n",
       "      <td>02x 132x689\"</td>\n",
       "      <td>529</td>\n",
       "      <td>tower</td>\n",
       "      <td>180.0\"</td>\n",
       "      <td>n</td>\n",
       "      <td>1792</td>\n",
       "      <td>...</td>\n",
       "      <td>mhz</td>\n",
       "      <td>2145-2155,1736- 1740</td>\n",
       "      <td>1745-12715460. 2135-</td>\n",
       "      <td>o</td>\n",
       "      <td>1808</td>\n",
       "      <td>3</td>\n",
       "      <td>wrong_num_columns</td>\n",
       "      <td>n</td>\n",
       "      <td>na</td>\n",
       "      <td>hard line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>na</td>\n",
       "      <td>rrurrh</td>\n",
       "      <td>ericsson</td>\n",
       "      <td>radio 4478 b71</td>\n",
       "      <td>16x 132 x74\"</td>\n",
       "      <td>600</td>\n",
       "      <td>tower</td>\n",
       "      <td>180.0</td>\n",
       "      <td>nn</td>\n",
       "      <td>179.4</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>nia</td>\n",
       "      <td>na</td>\n",
       "      <td>no</td>\n",
       "      <td>180.6</td>\n",
       "      <td>3</td>\n",
       "      <td>wrong_num_columns</td>\n",
       "      <td>nn</td>\n",
       "      <td>na</td>\n",
       "      <td>coax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type Manufacturer            Model #       Dimensions HxWxD  \\\n",
       "0   None    DISH-HP          RFS          SB6-W60BC  6.23' x 6.23' x 2.98'   \n",
       "1   None    DISH-HP    Commscope          USX10-11W       10.00' x -' x -'   \n",
       "2   None  Radio/ODU      Ceragon              RFU-D     9.1\" x 9.2\" x 3.9\"   \n",
       "3   None  Radio/ODU      Ceragon     FibeAir IP-20E     9.2\" x 9.1\" x 3.9\"   \n",
       "4   None    DISH-HP          RFS            SB4-W60     4.14' x 4.14' x -'   \n",
       "5   None  Radio/ODU      Ceragon     FibeAir IP-20E     9.2\" x 9.1\" x 3.9\"   \n",
       "6     na      panel      cellmax      cmabigs21/e06          81.1'x7.7'x48   \n",
       "7     na      panel          rfs  apxvaa24_43-u-a20             96'x24'x85   \n",
       "8     na        tta          rfs      atm1900d-1cwa               86x10x26   \n",
       "9     na     rrurrh     ericsson              rruz2           202x132 x69\"   \n",
       "10    na     rrurrh     ericsson              rru22           02x 132x689\"   \n",
       "11    na     rrurrh     ericsson     radio 4478 b71           16x 132 x74\"   \n",
       "\n",
       "   Weight(lbs.) Location RAD Center AGL Equipment Tip Height  \\\n",
       "0         198.0    Tower         155.0'               158.1'   \n",
       "1         579.8    Tower         155.0'               160.0'   \n",
       "2          14.3    Tower         155.0'               155.4'   \n",
       "3          14.3    Tower         155.0'               155.4'   \n",
       "4          77.0    Tower         125.0'               127.1'   \n",
       "5          14.3    Tower         125.0'               125.4'   \n",
       "6           350   tower,         180.0\"                   na   \n",
       "7          1014   tower,         180.0\"                  111   \n",
       "8            84    tower          180.0                   nn   \n",
       "9           529    tower         180.0\"                    1   \n",
       "10          529    tower         180.0\"                    n   \n",
       "11          600    tower          180.0                   nn   \n",
       "\n",
       "   Equipment Base Height  ... TX/RX Frequency Units  \\\n",
       "0                 151.9'  ...                   MHz   \n",
       "1                 150.0'  ...                   GHz   \n",
       "2                 154.6'  ...                   N/A   \n",
       "3                 154.6'  ...                   N/A   \n",
       "4                 122.9'  ...                   MHz   \n",
       "5                 124.6'  ...                   N/A   \n",
       "6                   1766  ...                   mhz   \n",
       "7                  1760  ...                   mhz   \n",
       "8                   1796  ...                    na   \n",
       "9                   1792  ...                   mhz   \n",
       "10                  1792  ...                   mhz   \n",
       "11                 179.4  ...                    na   \n",
       "\n",
       "                    TX Frequency                 RX Frequency  \\\n",
       "0                           6400                         6400   \n",
       "1                             11                            1   \n",
       "2                            N/A                          N/A   \n",
       "3                            N/A                          N/A   \n",
       "4                           6400                         6400   \n",
       "5                            N/A                          N/A   \n",
       "6   1930-1945.2145- 215517351740  11875505-12816355,21174450-   \n",
       "7                        668-638                       622642   \n",
       "8                            nia                           na   \n",
       "9            21452155, 1736 1740             74512715450 2135   \n",
       "10          2145-2155,1736- 1740         1745-12715460. 2135-   \n",
       "11                           nia                           na   \n",
       "\n",
       "   Using Unlicensed Frequencies?      Equipment Gain Total # of Lines  \\\n",
       "0                             No    35.7/ 36.7/ 37.3                1   \n",
       "1                             No                 N/A                0   \n",
       "2                             No                 N/A                4   \n",
       "3                             No                 N/A                0   \n",
       "4                             No  32.4 / 32.7 / 33.4                1   \n",
       "5                             No                 N/A                0   \n",
       "6                             no                1834                6   \n",
       "7                             no                1840                3   \n",
       "8                             no               1804                1   \n",
       "9                             no                1808                2   \n",
       "10                             o                1808                3   \n",
       "11                            no               180.6                3   \n",
       "\n",
       "   Line Quant. Per Azimuth/Sector Line Type   Line Diameter Size  \\\n",
       "0                               1      Coax   0.29\" (7.2mm) RG-8   \n",
       "1                             N/A       N/A                  N/A   \n",
       "2             See Config. Summary  Multiple  See Config. Summary   \n",
       "3                             N/A       N/A                  N/A   \n",
       "4                               1      Coax   0.29\" (7.2mm) RG-8   \n",
       "5                             N/A       N/A                  N/A   \n",
       "6               wrong_num_columns        na       18.31 18.7/192   \n",
       "7               wrong_num_columns        nn              132/136   \n",
       "8               wrong_num_columns     11000                    2   \n",
       "9               wrong_num_columns         2                   na   \n",
       "10              wrong_num_columns         n                   na   \n",
       "11              wrong_num_columns        nn                   na   \n",
       "\n",
       "                                   Line Configuration  \n",
       "0                                                 N/A  \n",
       "1                                                 N/A  \n",
       "2   2 - Control Cable;\\n0.31\" (7.8mm) Cable;\\n2\\n2...  \n",
       "3                                                 N/A  \n",
       "4                                                 N/A  \n",
       "5                                                 N/A  \n",
       "6                                                coax  \n",
       "7                                                coax  \n",
       "8                                        fiberfhybrid  \n",
       "9                                            conduit  \n",
       "10                                          hard line  \n",
       "11                                               coax  \n",
       "\n",
       "[12 rows x 24 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_exhibit.sections['ground space requirements']['data']\n",
    "old_exhibit.sections['backup power requirements']['data']\n",
    "old_exhibit.sections['utility requirements']['data']\n",
    "old_exhibit.sections['transmitter & receiver specifications']['data']\n",
    "old_exhibit.sections['equipment specifications']['data']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
