{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "1. Extract/organize line configuration and conduit configuration data from old_exhibit\n",
    "2. Write pdf_comparison class\n",
    "3. Write pdf_markup class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pdfminer.six\n",
    "%pip install pdfplumber\n",
    "%pip install numpy pandas\n",
    "%pip install textdistance\n",
    "%pip install regex\n",
    "%pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipympl\n",
    "%pip install reportlab>=3.6.2\n",
    "%pip install PyPDF2\n",
    "%pip install ocrmypdf\n",
    "%pip install pdf2jpg\n",
    "%pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_pages, extract_text\n",
    "from pdfminer.layout import LTTextContainer, LTChar, LTRect, LTFigure\n",
    "# To extract text from tables in PDF\n",
    "import pdfplumber\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Iterable, Dict, Tuple\n",
    "import regex\n",
    "from textdistance import hamming, jaro, levenshtein\n",
    "import yaml\n",
    "import itertools\n",
    "\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "os.environ['USE_TORCH'] = '1'\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "from PIL import Image\n",
    "from PyPDF2 import PdfMerger\n",
    "from ocrmypdf.hocrtransform import HocrTransform\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pdf_data():\n",
    "    def __init__(self,   \n",
    "                 orig_filepath: str | Path, \n",
    "                 ocr_filepath:  str | Path, \n",
    "                 config:        str | Path,\n",
    "                 key_val_sep:   str = ':' ,) -> None:\n",
    "        self.orig_filepath = orig_filepath\n",
    "        self.ocr_filepath = ocr_filepath\n",
    "        self.config = config  \n",
    "        self.text_df = None  \n",
    "        self.px_col_sep = 8\n",
    "        self.px_word_sep = 2\n",
    "        self.col_sep_str = ' | '\n",
    "        self.key_val_sep = key_val_sep\n",
    "\n",
    "    def combine_key_value_pairs_in_words_df(self, words_df):\n",
    "        drop_idxs = list()\n",
    "        for wIdx, word in words_df.iterrows():\n",
    "            test = (word['text'][-1] == self.key_val_sep) and \\\n",
    "                    (wIdx != words_df.index[-1]) and \\\n",
    "                    (words_df.loc[wIdx+1, 'top'] == word['top'])  \n",
    "            if test:\n",
    "                drop_idxs.append(wIdx+1)\n",
    "                words_df.loc[wIdx, 'text'] = f\"{word['text']}{words_df.loc[wIdx+1, 'text']}\"  \n",
    "                words_df.loc[wIdx, 'right'] = words_df.loc[wIdx+1, 'right']       \n",
    "        words_df = words_df.drop(drop_idxs).reset_index(drop=True)    \n",
    "\n",
    "        return words_df\n",
    "\n",
    "    def fill_implicit_keys(self, section_header, left_mult=2, right_mult=2):\n",
    "        section_dict = self.sections[section_header]\n",
    "        for sub_idx, subsection_bounds in section_dict['bounds'].iterrows():    \n",
    "            mask = (self.text_df['norm_y_top'   ] > subsection_bounds['y_top'   ]) & \\\n",
    "                   (self.text_df['norm_y_bottom'] < subsection_bounds['y_bottom']) \n",
    "            subsect_df = self.text_df.loc[mask, :]\n",
    "\n",
    "            if any(subsect_df['source'] == 'ocr'):\n",
    "                page = pdfplumber.open(self.ocr_filepath ).pages[subsect_df.loc[subsect_df.index[0], 'page']]\n",
    "            else:\n",
    "                page = pdfplumber.open(self.orig_filepath).pages[subsect_df.loc[subsect_df.index[0], 'page']]\n",
    "            \n",
    "            words_df = self.get_words_df(page, subsect_df['y_top'].min(), subsect_df['y_bottom'].max())\n",
    "            words_df.loc[:, 'top'] = np.round(words_df['top']) \n",
    "            words_df.sort_values(by=['top', 'left'], ignore_index=True, inplace=True)   \n",
    "\n",
    "            words_df = self.combine_key_value_pairs_in_words_df(words_df)\n",
    "\n",
    "            split_lines     = list()\n",
    "            split_lines_row = list()\n",
    "            split_lines_col = list()\n",
    "            drop_idxs = list()\n",
    "            for rIdx, line in subsect_df.iterrows():\n",
    "                text_by_col = line['text'].split(self.col_sep_str)\n",
    "                split_lines.extend(text_by_col)\n",
    "                split_lines_row.extend([rIdx for k in range(len(text_by_col))])\n",
    "                split_lines_col.extend(list(range(len(text_by_col))))\n",
    "                \n",
    "                # combine words_df to match phrases in split_lines\n",
    "                for tIdx, token in enumerate(text_by_col):\n",
    "                    combine_idxs = [idx for idx, word in words_df.iterrows() \n",
    "                                    if  word['text'] in token\n",
    "                                    and word['top']+0.5 >= line['y_top']\n",
    "                                    and word['bottom'] <= line['y_bottom']]\n",
    "                    tmp_df = words_df.loc[combine_idxs, :]\n",
    "                    \n",
    "                    first_word = token.split(' ')[0]\n",
    "                    possible_start_idx = tmp_df.index[tmp_df['text'] == first_word]\n",
    "                    for start_idx in possible_start_idx:\n",
    "                        phrase_idxs = range(start_idx, start_idx+len(token.split(' ')))\n",
    "                        if all([True if idx in tmp_df.index else False for idx in phrase_idxs]): \n",
    "                            phrase = ' '.join(tmp_df.loc[phrase_idxs, 'text'])\n",
    "                            if phrase == token:\n",
    "                                words_df.loc[start_idx, ['text', 'right']] = [phrase, tmp_df.loc[phrase_idxs[-1], 'right']]\n",
    "                                drop_idxs.extend(phrase_idxs[1:])             \n",
    "                                break                                  \n",
    "            words_df = words_df.drop(drop_idxs).reset_index(drop=True)\n",
    "\n",
    "            assert all([True if phrase==token else False for phrase, token in zip(split_lines, words_df['text'])])\n",
    "\n",
    "            for token, rIdx, cIdx, (wIdx, word) in zip(split_lines, split_lines_row, split_lines_col, words_df.iterrows()):\n",
    "                if self.key_val_sep in token:\n",
    "                    continue\n",
    "                token_bounds = word[['left', 'right']]\n",
    "                col_mask = ((words_df['right' ]- token_bounds['left'] > -left_mult*self.px_col_sep) & \\\n",
    "                            (words_df['left' ] - token_bounds['left'] <=  0                )) | \\\n",
    "                           ((words_df['right'] - token_bounds['right'] < right_mult*self.px_col_sep) & \\\n",
    "                            (words_df['right'] - token_bounds['right'] >= 0                ))\n",
    "                same_column_tokens = words_df.loc[col_mask, 'text']\n",
    "                \n",
    "                implicit_key = [item.split(self.key_val_sep)[0] for item in same_column_tokens.values if len(item.split(self.key_val_sep)) == 2]\n",
    "                if len(implicit_key) >= 1:\n",
    "                    original_text = self.text_df.loc[rIdx, 'text']\n",
    "                    text_cols = original_text.split(self.col_sep_str)\n",
    "                    text_cols[cIdx] = f'{implicit_key[0]}{self.key_val_sep}{text_cols[cIdx]}'\n",
    "                    self.text_df.loc[rIdx, 'text'] = self.col_sep_str.join(text_cols)  \n",
    "\n",
    "    def identify_line_merge_sets(self, text_df=None):\n",
    "        \n",
    "        if text_df is None:\n",
    "            text_df = self.text_df\n",
    "        \n",
    "        merge_sets = list()\n",
    "        for idx, line in text_df.iterrows():\n",
    "            merge_set = np.where((text_df['norm_y_top']    < line['norm_y_bottom']) &\n",
    "                                 (text_df['norm_y_top']    > line['norm_y_top']   )  )[0]\n",
    "            merge_set = text_df.index[merge_set]\n",
    "            if len(merge_set) > 0:\n",
    "                merge_set = [idx] + merge_set.to_list()\n",
    "                same_merge_set   = any([True if m_set == merge_set else False for m_set in merge_sets])\n",
    "                overlapping_sets = [set_idx for set_idx, m_set in enumerate(merge_sets) if any(i for i in m_set if i in merge_set)]\n",
    "                if same_merge_set:\n",
    "                    continue\n",
    "                elif len(overlapping_sets) == 1:\n",
    "                    merge_sets[overlapping_sets[0]] = np.unique(merge_sets[overlapping_sets[0]] + merge_set).tolist() \n",
    "                elif len(overlapping_sets) > 1:\n",
    "                    print('Have not written code to manage more than one overlapping set when combining lines')\n",
    "                else:\n",
    "                    merge_sets.append(merge_set)\n",
    "        return merge_sets\n",
    "    \n",
    "    def get_words_df(self, page, y_top, y_bottom):\n",
    "        page_crop = page.within_bbox((         0, y_top, \n",
    "                                        page.width, y_bottom))  \n",
    "\n",
    "        words = page_crop.extract_words()  \n",
    "        words_dict = dict(text=[], left=[], right=[], top=[], bottom=[])\n",
    "        for word in words:\n",
    "            if word['text'] == '|':\n",
    "                continue\n",
    "            word['text'] = word['text'].lower().replace('|','')\n",
    "            for dict_key, word_key in zip(['text', 'left', 'right', 'top', 'bottom'],\n",
    "                                            ['text',   'x0',    'x1', 'top', 'bottom']):\n",
    "                words_dict[dict_key].append(word[word_key])\n",
    "        \n",
    "        words_df = pd.DataFrame.from_dict(words_dict)\n",
    "        words_df.sort_values(by='left', ignore_index=True, inplace=True)\n",
    "\n",
    "        return words_df\n",
    "\n",
    "    def identify_columns_from_words_df(self, words_df):\n",
    "        col_id = []\n",
    "        col_num = 0\n",
    "        prev_w_info = None\n",
    "        for w_idx, w_info in words_df.iterrows():\n",
    "            if prev_w_info is not None: \n",
    "                if (w_info['left'] - prev_w_info['right'] > self.px_col_sep):\n",
    "                    col_num += 1\n",
    "                elif (w_info['left'] - prev_w_info['right'] < 0):\n",
    "                    w_info['right'] = prev_w_info['right'] \n",
    "            col_id.append(col_num)\n",
    "            prev_w_info = w_info.copy()\n",
    "        words_df['col_id'] = col_id\n",
    "        words_df.sort_values(by=['col_id', 'top', 'left'], ignore_index=True, inplace=True)\n",
    "\n",
    "        col_phrases = []\n",
    "        for col_id in words_df['col_id'].unique():\n",
    "            col_df = words_df.loc[words_df['col_id'] == col_id, :]\n",
    "            col_phrases.append(' '.join(col_df['text']))\n",
    "\n",
    "        return col_phrases \n",
    "\n",
    "    def organize_single_lines(self, merge_sets, ocr_pdf, orig_pdf):\n",
    "        merge_list = list(itertools.chain.from_iterable(merge_sets))\n",
    "        for idx, line in self.text_df.iterrows():\n",
    "            if idx not in merge_list:   \n",
    "                if line['source'] == 'ocr':\n",
    "                    page = ocr_pdf.pages [line['page']]\n",
    "                else:\n",
    "                    page = orig_pdf.pages[line['page']]\n",
    "\n",
    "                words_df = self.get_words_df(page, line['y_top'], line['y_bottom'])\n",
    "                words_df.loc[:, 'top'] = np.round(words_df['top']) \n",
    "\n",
    "                words_df = self.combine_key_value_pairs_in_words_df(words_df)\n",
    "\n",
    "                col_phrases = self.identify_columns_from_words_df(words_df)\n",
    "\n",
    "                self.text_df.loc[idx, 'text'] = self.col_sep_str.join(col_phrases)\n",
    "\n",
    "    def combine_merge_sets(self, merge_sets, ocr_pdf, orig_pdf):\n",
    "\n",
    "        drop_idxs = list()\n",
    "        for merge_set in merge_sets:\n",
    "            partial_df = self.text_df.loc[merge_set, :]\n",
    "            y_top    = partial_df['y_top'].min()    \n",
    "            y_bottom = partial_df['y_bottom'].max()\n",
    "\n",
    "            if any(partial_df['source'] == 'ocr'):\n",
    "                page = ocr_pdf.pages [partial_df.loc[merge_set[0], 'page']]\n",
    "            else:\n",
    "                page = orig_pdf.pages[partial_df.loc[merge_set[0], 'page']]\n",
    "\n",
    "            words_df = self.get_words_df(page, y_top, y_bottom)\n",
    "            \n",
    "            col_phrases = self.identify_columns_from_words_df(words_df)\n",
    "\n",
    "            # replace first line in merge set with merged text and position info, then store indices of \n",
    "            # remaining merge set to drop at end of combine method\n",
    "            self.text_df.loc[merge_set[0], \n",
    "                             ['text', 'y_bottom', 'x_left', 'x_right', 'norm_y_bottom',]] = [self.col_sep_str.join(col_phrases),\n",
    "                                                                                             partial_df['y_bottom'].max(),\n",
    "                                                                                             partial_df['x_left'].min(),\n",
    "                                                                                             partial_df['x_right'].max(),\n",
    "                                                                                             partial_df['norm_y_bottom'].max(),] \n",
    "\n",
    "            drop_idxs.extend(merge_set[1:])             \n",
    "\n",
    "        self.text_df = self.text_df.drop(drop_idxs).reset_index(drop=True)\n",
    "\n",
    "    def organize_text_lines_by_row_and_column(self):\n",
    "        merge_sets = self.identify_line_merge_sets()\n",
    "        ocr_pdf  = pdfplumber.open(self.ocr_filepath)\n",
    "        orig_pdf = pdfplumber.open(self.orig_filepath) \n",
    "        self.organize_single_lines(merge_sets, ocr_pdf, orig_pdf)\n",
    "        self.combine_merge_sets   (merge_sets, ocr_pdf, orig_pdf)\n",
    "    \n",
    "    def split_text_lines_with_pdfplumber(self, pdf, element, page_idx, text_dict,):\n",
    "        did_split = False\n",
    "        page = pdf.pages[page_idx]\n",
    "        page_crop = page.within_bbox((         0, page.height - element.y1, \n",
    "                                      page.width, page.height - element.y0))  \n",
    "\n",
    "        text = page_crop.extract_text_lines()\n",
    "        \n",
    "        if len(text) > 1:\n",
    "            did_split = True\n",
    "            for line in text:\n",
    "\n",
    "                norm_y_top    = page_idx + (line['top'   ] / page.height)\n",
    "                norm_y_bottom = page_idx + (line['bottom'] / page.height)\n",
    "                if np.logical_not(np.any((np.isclose(self.text_df['norm_y_top'   ], norm_y_top   , atol=1e-2)) &\n",
    "                                         (np.isclose(self.text_df['norm_y_bottom'], norm_y_bottom, atol=1e-2))  )):\n",
    "                    text_dict['page'         ].append(page_idx)\n",
    "                    text_dict['y_bottom'     ].append(line['bottom'])\n",
    "                    text_dict['y_top'        ].append(line['top'])\n",
    "                    text_dict['x_left'       ].append(line['x0'])\n",
    "                    text_dict['x_right'      ].append(line['x1'])\n",
    "                    text_dict['text'         ].append(line['text'].lower().replace('|', ''))\n",
    "                    text_dict['norm_y_top'   ].append(norm_y_top)\n",
    "                    text_dict['norm_y_bottom'].append(norm_y_bottom)\n",
    "                    text_dict['source'       ].append('ocr')\n",
    "\n",
    "                    print(f'\\nstoring text from OCR on page {page_idx}:\\n\"{line['text'].lower()}\"')\n",
    "\n",
    "        return did_split    \n",
    "\n",
    "    def get_text_lines_from_original(self):\n",
    "        pdf = pdfplumber.open(self.orig_filepath)\n",
    "        text_dict = dict(text=[], source=[], page=[], y_top=[], y_bottom=[], x_left=[], x_right=[], norm_y_top=[], norm_y_bottom=[],)\n",
    "        for page_idx, page in enumerate(pdf.pages):\n",
    "            text_lines = page.extract_text_lines()\n",
    "            for line in text_lines:\n",
    "                norm_y_top    = page_idx + (line['top'   ] / page.height)\n",
    "                norm_y_bottom = page_idx + (line['bottom'] / page.height)\n",
    "\n",
    "                text_dict['page'         ].append(page_idx)\n",
    "                text_dict['y_bottom'     ].append(line['bottom'])\n",
    "                text_dict['y_top'        ].append(line['top'])\n",
    "                text_dict['x_left'       ].append(line['x0'])\n",
    "                text_dict['x_right'      ].append(line['x1'])\n",
    "                text_dict['text'         ].append(line['text'].lower().replace('|', ''))\n",
    "                text_dict['norm_y_top'   ].append(norm_y_top)\n",
    "                text_dict['norm_y_bottom'].append(norm_y_bottom)\n",
    "                text_dict['source'       ].append('original')\n",
    "                text_dict['confidence'   ].append(1.0)\n",
    "        \n",
    "        if self.text_df is None:\n",
    "            self.text_df = pd.DataFrame(text_dict)\n",
    "        else:\n",
    "            tmp_text_df = pd.DataFrame(text_dict)\n",
    "            self.text_df = pd.concat((self.text_df, tmp_text_df), axis=0, ignore_index=True)\n",
    "\n",
    "        self.text_df.sort_values(by='norm_y_top', inplace=True, ignore_index=True, ascending=True)\n",
    "\n",
    "    def get_text_lines_from_ocr(self, pages: Optional[Iterable[int]] = None) -> pd.DataFrame:\n",
    "        text_dict = dict(text=[], source=[], page=[], y_top=[], y_bottom=[], x_left=[], x_right=[], norm_y_top=[], norm_y_bottom=[], confidence=[])\n",
    "        for page_idx, page in enumerate(self.ocr_text['pages']):\n",
    "            for block in page['blocks']:\n",
    "                for line in block['lines']:\n",
    "                    for word in line['words']:\n",
    "                        text_dict['page'         ].append(page_idx)\n",
    "                        text_dict['y_bottom'     ].append(page['dimensions'][0] * word['geometry'][1][1])\n",
    "                        text_dict['y_top'        ].append(page['dimensions'][0] * word['geometry'][0][1])\n",
    "                        text_dict['x_left'       ].append(word['geometry'][0][0])\n",
    "                        text_dict['x_right'      ].append(word['geometry'][1][0])\n",
    "                        text_dict['text'         ].append(word['value'].lower())\n",
    "                        text_dict['norm_y_top'   ].append(word['geometry'][0][1])\n",
    "                        text_dict['norm_y_bottom'].append(word['geometry'][1][1])\n",
    "                        text_dict['confidence'   ].append(word['confidence'])\n",
    "                        text_dict['source'       ].append('ocr') \n",
    "        ocr_text_df = pd.DataFrame(text_dict)\n",
    "        #TODO Need to merge words into phrases and columns directly from ocr_text_df. Use identfy_line_merge_sets as a guide\n",
    "        # merge_sets = self.identify_line_merge_sets(text_df=ocr_text_df)\n",
    "        \n",
    "        \n",
    "        if self.text_df is None:\n",
    "            self.text_df = pd.DataFrame(text_dict)\n",
    "        elif len(text_dict['text']) > 0:\n",
    "            tmp_text_df  = pd.DataFrame(text_dict)\n",
    "            self.text_df = pd.concat((self.text_df, tmp_text_df), axis=0, ignore_index=True)\n",
    "\n",
    "        self.text_df.sort_values(by='norm_y_top', inplace=True, ignore_index=True, ascending=True)\n",
    "\n",
    "    def get_text_lines_from_ocr_AFTER_TESSERACT(self, pages: Optional[Iterable[int]] = None) -> pd.DataFrame:\n",
    "        text_dict = dict(text=[], source=[], page=[], y_top=[], y_bottom=[], x_left=[], x_right=[], norm_y_top=[], norm_y_bottom=[],)\n",
    "        for page_idx, page in enumerate(extract_pages(self.ocr_filepath)):\n",
    "            pdf = pdfplumber.open(self.ocr_filepath)\n",
    "            for el_idx, element in enumerate(page):\n",
    "                if isinstance(element, LTTextContainer):\n",
    "                    did_split = self.split_text_lines_with_pdfplumber(pdf, element, page_idx, text_dict)\n",
    "                    if not did_split:\n",
    "                        y_top = page.height - element.y1\n",
    "                        y_bottom = page.height - element.y0 \n",
    "                        norm_y_top    = page_idx + y_top    / page.height\n",
    "                        norm_y_bottom = page_idx + y_bottom / page.height\n",
    "                        if np.logical_not(np.any((np.isclose(self.text_df['norm_y_top'   ], norm_y_top   , atol=1e-2)) &\n",
    "                                                 (np.isclose(self.text_df['norm_y_bottom'], norm_y_bottom, atol=1e-2))  )):\n",
    "                            text_dict['page'         ].append(page_idx)\n",
    "                            text_dict['y_bottom'     ].append(y_bottom)\n",
    "                            text_dict['y_top'        ].append(y_top)\n",
    "                            text_dict['x_left'       ].append(element.x0)\n",
    "                            text_dict['x_right'      ].append(element.x1)\n",
    "                            text_dict['text'         ].append(element.get_text().lower().replace('\\n', '').replace('|', ''))\n",
    "                            text_dict['norm_y_top'   ].append(norm_y_top)\n",
    "                            text_dict['norm_y_bottom'].append(norm_y_bottom)\n",
    "                            text_dict['source'       ].append('ocr')\n",
    "    \n",
    "                            print(f'\\nstoring text from OCR on page {page_idx}:\\n\"{element.get_text().lower().replace('\\n', '')}\"')\n",
    "\n",
    "                elif isinstance(element, LTRect):\n",
    "                    print(f'page = {page_idx}, ypos={element.y0}, type={type(element)}')\n",
    "                else:\n",
    "                    print(f'page = {page_idx}, ypos={element.y0}, type={type(element)}')\n",
    "\n",
    "        if self.text_df is None:\n",
    "            self.text_df = pd.DataFrame(text_dict)\n",
    "        elif len(text_dict['text']) > 0:\n",
    "            tmp_text_df  = pd.DataFrame(text_dict)\n",
    "            self.text_df = pd.concat((self.text_df, tmp_text_df), axis=0, ignore_index=True)\n",
    "\n",
    "        self.text_df.sort_values(by='norm_y_top', inplace=True, ignore_index=True, ascending=True)\n",
    "\n",
    "    def get_section_headers(self):\n",
    "        with open(self.config, 'r') as file:\n",
    "            self.config_data = yaml.safe_load(file) \n",
    "        \n",
    "        self.sections = dict()\n",
    "        for section in self.config_data['sections']:\n",
    "            self.sections[section['header']] = dict(bounds = pd.DataFrame(),\n",
    "                                                    extract = section['extract'])\n",
    "            for key in section.keys():\n",
    "                if key in ['header', 'extract']: continue\n",
    "                self.sections[section['header']][key] = section[key]\n",
    "\n",
    "    def get_section_bounds(self):\n",
    "\n",
    "        self.get_section_headers()\n",
    "\n",
    "        # detect start and end of sections\n",
    "        prev_section_info = dict(header=None, df_row=None)\n",
    "        prev_page = 0\n",
    "        for row_idx, text_data in self.text_df.iterrows():\n",
    "            detected_section = None\n",
    "            for header in self.sections.keys():\n",
    "                match = regex.search(f'{header}{{s<=3,i<=3,d<=3}}', text_data['text'], regex.BESTMATCH)    \n",
    "                if match is not None:\n",
    "                    detected_section = header\n",
    "                    break\n",
    "\n",
    "            if text_data['page'] > prev_page or detected_section is not None:\n",
    "                if prev_section_info['header'] is not None:   # store end of sections\n",
    "                    prev_df_idx = self.sections[prev_section_info['header']]['bounds'].index[-1] \n",
    "                    prev_bottom = prev_page+0.9999 if (text_data['page'] > prev_page) else text_data['norm_y_top'] \n",
    "                    self.sections[prev_section_info['header']]['bounds'].loc[prev_df_idx, ['y_bottom',]] = [prev_bottom]\n",
    "                # store start of sections\n",
    "                top = text_data['page'] if (text_data['page'] > prev_page) else text_data['norm_y_top']\n",
    "                tmp_df = pd.DataFrame(data    = zip([top], [np.nan], [False]),\n",
    "                                      columns = ['y_top', 'y_bottom', 'data_extracted'],)\n",
    "                header = detected_section\n",
    "                self.sections[header]['bounds'] = pd.concat((self.sections[header]['bounds'], tmp_df), ignore_index=True)\n",
    "                prev_section_info['header'] = header\n",
    "                if text_data['page'] > prev_page:\n",
    "                    prev_page+=1\n",
    "            prev_section_info['df_row'] = row_idx\n",
    "        \n",
    "        # store end of final section\n",
    "        prev_y_bottom = self.text_df.loc[prev_section_info['df_row'], 'norm_y_bottom']\n",
    "        prev_df_idx = self.sections[prev_section_info['header']]['bounds'].index[-1] \n",
    "        self.sections[prev_section_info['header']]['bounds'].loc[prev_df_idx, ['y_bottom',]] = [np.ceil(prev_y_bottom),]\n",
    "    \n",
    "    def extract_table(self, subsection_bounds):  \n",
    "        page_num = int(np.floor(subsection_bounds['y_top'])) \n",
    "        pdf = pdfplumber.open(self.orig_filepath)\n",
    "        table_page = pdf.pages[page_num]\n",
    "        table_crop = table_page.within_bbox((               0, (subsection_bounds['y_top'   ]-page_num)*table_page.height, \n",
    "                                             table_page.width, (subsection_bounds['y_bottom']-page_num)*table_page.height))\n",
    "        table = table_crop.extract_table()\n",
    "        # print((subsection_bounds['y_top'   ]-page_num)*table_page.height, (subsection_bounds['y_bottom']-page_num)*table_page.height, table)\n",
    "        return table\n",
    "    \n",
    "    def extract_text_lines_from_original(self, subsection_bounds):\n",
    "        page_num = int(np.floor(subsection_bounds['y_top'])) \n",
    "        pdf = pdfplumber.open(self.orig_filepath)\n",
    "        page = pdf.pages[page_num]\n",
    "        page_crop = page.within_bbox((         0, (subsection_bounds['y_top'   ]-page_num)*page.height, \n",
    "                                      page.width, (subsection_bounds['y_bottom']-page_num)*page.height))  \n",
    "\n",
    "        text = page_crop.extract_text_lines()\n",
    "\n",
    "        for line in text:\n",
    "            line['norm_y_top']    = page_num + (line['top']    / page.height)\n",
    "            line['norm_y_bottom'] = page_num + (line['bottom'] / page.height)\n",
    "            line['page']          = page_num\n",
    "            line['y_bottom']      = page.height - line['bottom']\n",
    "            line['y_top']         = page.height - line['top']\n",
    "            line['text'] = line['text'].lower().replace('|', '')\n",
    "\n",
    "        return text  \n",
    "\n",
    "    def table_to_df(self, \n",
    "                    table: List[List[str]], \n",
    "                    extract_params: str | Dict | List[Dict],\n",
    "                    ) -> pd.DataFrame:\n",
    "        if type(extract_params) == str and 'col' in extract_params.lower():\n",
    "            info_keys = list()\n",
    "            data = list()\n",
    "            for row in table:\n",
    "                iKey = row.pop(0)\n",
    "                info_keys.append(iKey.replace('\\n', ' '))\n",
    "                data.append(row)\n",
    "            df = pd.DataFrame(data=np.array(data).transpose(), columns=info_keys)\n",
    "\n",
    "        elif type(extract_params) == str and 'row' in extract_params.lower():\n",
    "            info_keys = table[0]\n",
    "            data = table[1:]\n",
    "            df = pd.DataFrame(data=data, columns=info_keys)\n",
    "\n",
    "        else:\n",
    "            print('There is no method implemented for converting data with this extraction method to a DataFrame')\n",
    "            df = None\n",
    "        \n",
    "        return df \n",
    " \n",
    "    def extract_table_data(self):\n",
    "        for section_header, section_dict in self.sections.items():\n",
    "            for sub_idx, subsection_bounds in section_dict['bounds'].iterrows():\n",
    "                if subsection_bounds['data_extracted']:\n",
    "                    continue\n",
    "\n",
    "                table = self.extract_table(subsection_bounds)\n",
    "                if table is not None:\n",
    "                    data_df = self.table_to_df(table, section_dict['extract'])\n",
    "                    data_df = data_df.loc[:, [col for col in data_df.columns if col.lower() != section_header]]\n",
    "                    if 'data' in section_dict.keys(): \n",
    "                        section_dict['data'] = pd.concat((section_dict['data'], data_df),\n",
    "                                                         axis=0,\n",
    "                                                         ignore_index=True)\n",
    "                    else:\n",
    "                        section_dict['data'] = data_df\n",
    "                    \n",
    "                    section_dict['bounds'].loc[sub_idx, 'data_extracted'] = True\n",
    "\n",
    "    def align_data_to_existing_df(self,\n",
    "                                  section_dict: Dict,\n",
    "                                  subsect_df: pd.DataFrame,\n",
    "                                 ):\n",
    "        if type(section_dict['extract']) == str and 'col' in section_dict['extract'].lower():\n",
    "            info_keys_to_match = list(section_dict['data'].columns)\n",
    "            original_info_keys = list(section_dict['data'].columns)\n",
    "            info_keys = list()\n",
    "            data      = list()\n",
    "            for text in subsect_df['text']:\n",
    "                row = text.split(self.col_sep_str)\n",
    "                iKey = row.pop(0)\n",
    "                iKey = iKey.replace('\\n', ' ')\n",
    "                match_score = np.array([levenshtein.normalized_similarity(iKey, matchKey) for matchKey in info_keys_to_match])\n",
    "                sorted_match_score, sorted_info_keys = zip(*sorted(zip(match_score, info_keys_to_match), reverse=True))\n",
    "                if iKey == 'equipment tip':\n",
    "                    stop = []\n",
    "                try:\n",
    "                    top_key_matches = sorted_info_keys[:3]\n",
    "                    \n",
    "                    #correct any instances in which OCR dropped the last word (probably b/c it was on a second line), causing poor matching\n",
    "                    if (len(iKey.split(' ')) == len(top_key_matches[0].split(' ')) \n",
    "                        and any([len(iKey.split(' ')) < len(key.split(' ')) for key in top_key_matches])):\n",
    "                        match_score = np.array([levenshtein.normalized_similarity(iKey, ' '.join(matchKey.split(' ')[:-1])) for matchKey in info_keys_to_match])\n",
    "            \n",
    "                    matched_key = info_keys_to_match.pop(np.where(match_score == match_score.max())[0][0])\n",
    "                    info_keys.append(matched_key)\n",
    "                    data.append(row)\n",
    "                    print(iKey, matched_key)\n",
    "                except:\n",
    "                    print(f'\\nNo matched key: iKey={iKey}, text={text}')\n",
    "            \n",
    "            # Add dummy data for unmatched keys\n",
    "            for key in info_keys_to_match:\n",
    "                info_keys.append(key)\n",
    "                data.append(['data_not_found' for k in range(expected_num_items)])\n",
    "\n",
    "            expected_num_items = pd.Series([len(d) for d in data]).mode()[0]\n",
    "            wrong_count_info = [(idx, len(d)) for idx, d in enumerate(data) if len(d) != expected_num_items]\n",
    "            for idx, num_items in wrong_count_info:\n",
    "                data[idx] = ['wrong_num_columns' for k in range(expected_num_items)]\n",
    "                print(f'\\n\"{info_keys[idx]}\" contained the wrong number of columns in the line.')\n",
    "\n",
    "            correct_order = [np.where(np.array(original_info_keys) == key)[0][0] for key in info_keys]\n",
    "            _, info_keys = zip(*sorted(zip(correct_order, info_keys)))\n",
    "            _, data      = zip(*sorted(zip(correct_order, data))) \n",
    "\n",
    "            data_df = pd.DataFrame(data=np.array(data).transpose(), columns=info_keys)\n",
    "            section_dict['data'] = pd.concat((section_dict['data'], data_df),\n",
    "                                              axis=0,\n",
    "                                              ignore_index=True)\n",
    "        return\n",
    "\n",
    "    def get_multilevel_key_value_pairs(self, section_dict, items):\n",
    "        filling_subheader = False\n",
    "        for item in items: \n",
    "            split_item = item.split(self.key_val_sep)\n",
    "            if len(split_item) == 2:\n",
    "                key, value = split_item\n",
    "                if len(value) == 0:\n",
    "                    value = None\n",
    "                else:\n",
    "                    value = value[1:]  if value[0]  == ' '  else value\n",
    "                    value = value[:-1] if value[-1] == '\\n' else value\n",
    "                    \n",
    "                if filling_subheader:\n",
    "                    section_dict['data'][stored_key][key] = value\n",
    "                    print(f'{stored_key} - {key}{self.key_val_sep} {value}')\n",
    "                else:\n",
    "                    section_dict['data'][key] = value     \n",
    "                    print(f'{key}{self.key_val_sep} {value}')\n",
    "            elif len(split_item) == 1:\n",
    "                stored_key = split_item[0]\n",
    "                section_dict['data'][stored_key] = dict()\n",
    "                filling_subheader = True\n",
    "\n",
    "    def extract_key_value_pairs(self, \n",
    "                                section_dict: Dict, \n",
    "                                subsect_df: pd.DataFrame, \n",
    "                                ) -> Dict:\n",
    "        section_dict['data'] = dict()\n",
    "        for l_idx, line in subsect_df.iterrows(): \n",
    "            items = line['text'].split(self.col_sep_str)\n",
    "            key_value_pairs = [item for item in items if len(item.split(self.key_val_sep)) == 2]\n",
    "            if len(key_value_pairs) == len(items):\n",
    "                for item in key_value_pairs:\n",
    "                    key, value = item.split(self.key_val_sep)\n",
    "                    if len(value) == 0:\n",
    "                        value = None\n",
    "                    else:\n",
    "                        value = value[1:]  if value[0]  == ' '  else value\n",
    "                        value = value[:-1] if value[-1] == '\\n' else value\n",
    "                    section_dict['data'][key] = value     \n",
    "                    print(f'{key}{self.key_val_sep} {value}') \n",
    "            else:\n",
    "                if line['source'] == 'original':\n",
    "                    pdf = pdfplumber.open(self.orig_filepath)\n",
    "                elif line['source'] == 'ocr':\n",
    "                    pdf = pdfplumber.open(self.ocr_filepath)\n",
    "                self.get_multilevel_key_value_pairs(section_dict, items)\n",
    "\n",
    "    def extract_text_data(self):\n",
    "        for section_header, section_dict in self.sections.items():\n",
    "            for sub_idx, subsection_bounds in section_dict['bounds'].iterrows():\n",
    "                if subsection_bounds['data_extracted']:\n",
    "                    continue\n",
    "\n",
    "                mask = (self.text_df['norm_y_top'   ] > subsection_bounds['y_top'   ]) & \\\n",
    "                       (self.text_df['norm_y_bottom'] < subsection_bounds['y_bottom']) \n",
    "                subsect_df = self.text_df.loc[mask, :]\n",
    "                \n",
    "                if 'data' in section_dict.keys() and type(section_dict['data']) == pd.DataFrame:\n",
    "                    self.align_data_to_existing_df(section_dict, subsect_df)\n",
    "                else:\n",
    "                    self.extract_key_value_pairs(section_dict, subsect_df)\n",
    "                \n",
    "                section_dict['bounds'].loc[sub_idx, 'data_extracted'] = True\n",
    "\n",
    "    def print_text(self):\n",
    "        max_x = 0\n",
    "        for page_text in self.text_containers:\n",
    "            for text_container in page_text:\n",
    "                if text_container.x1 > max_x:\n",
    "                    max_x = text_container.x1\n",
    "        for page_num, page_text in enumerate(self.text_containers):\n",
    "            print('###############################################')\n",
    "            print(f'Page {page_num}')\n",
    "            print('###############################################') \n",
    "            for text_container in page_text:  \n",
    "                text = text_container.get_text()\n",
    "                # print(f'{text_container.y0} to {text_container.y1}', text)\n",
    "                print(text_container.y1, text_container.y0, text)\n",
    "\n",
    "    def convert_pdf_page_to_image(fitz_doc, image_path, idx, zoom=4):\n",
    "        mat = fitz.Matrix(zoom, zoom)\n",
    "        page = fitz_doc.load_page(idx)\n",
    "        pix = page.get_pixmap(matrix=mat)\n",
    "        pix.save(image_path)\n",
    "\n",
    "    def write_ocr_text_to_pdfa(pdf_outpath, hocr_path, image_path):\n",
    "        hocr = HocrTransform(hocr_filename=hocr_path,\n",
    "                            dpi=1000,)\n",
    "        hocr.to_pdf(\n",
    "                    out_filename=pdf_outpath,\n",
    "                    image_filename=image_path,\n",
    "                    )\n",
    "        \n",
    "    def write_hocr_xml_file(hocr_path, page_xml):\n",
    "        with open(hocr_path, 'w') as f:\n",
    "            f.write(page_xml[0].decode())\n",
    "\n",
    "    def create_pdfa_with_ocr(self, output_dir, output_stem, ocr_xml, fitz_doc):\n",
    "        merger = PdfMerger()\n",
    "        with TemporaryDirectory(dir= Path(os.getcwd())) as tmpdir:\n",
    "            tmppath = Path(tmpdir)\n",
    "            for idx, page_xml in enumerate(ocr_xml): \n",
    "                hocr_path   = tmppath / f'{output_stem}_hocr_page{idx}.xml'\n",
    "                image_path  = tmppath / f'{output_stem}_image_page{idx}.png'\n",
    "                pdf_outpath = tmppath / f'{output_stem}_docTR_page{idx}.pdf'\n",
    "                self.write_hocr_xml_file(hocr_path, page_xml)\n",
    "                self.convert_pdf_page_to_image(fitz_doc, image_path, idx, zoom=4) \n",
    "                self.write_ocr_text_to_pdfa(pdf_outpath, hocr_path, image_path)\n",
    "                merger.append(pdf_outpath)\n",
    "            merger.write(output_dir / f'{output_stem}_docTR.pdf' )\n",
    "            merger.close()\n",
    "\n",
    "    def run_ocr(self, ocr_predictor):\n",
    "        output_base_path = self.orig_filepath.parent / self.orig_filepath.stem\n",
    "        doc_pages = DocumentFile.from_pdf(self.orig_filepath)\n",
    "        fitz_doc = fitz.open(self.orig_filepath)\n",
    "        ocr_text = ocr_predictor(doc_pages) \n",
    "        self.ocr_text = ocr_text.export()\n",
    "        ocr_xml = ocr_text.export_as_xml()\n",
    "        self.create_pdfa_with_ocr(output_dir  = self.orig_filepath.parent, \n",
    "                                  output_stem = self.orig_filepath.stem, \n",
    "                                  ocr_xml = ocr_xml, \n",
    "                                  fitz_doc = fitz_doc)   \n",
    "\n",
    "\n",
    "class ATC_amendment(pdf_data):\n",
    "    def __init__(self, \n",
    "                 orig_filepath: str | Path, \n",
    "                 ocr_filepath:  str | Path, \n",
    "                 config:        str | Path,\n",
    "                 key_val_sep:   str = ':' ,) -> None:        \n",
    "        super().__init__(orig_filepath, ocr_filepath, config, key_val_sep)\n",
    "\n",
    "    def extract_line_config_data_from_cells_containing_all_key_value_pairs(self, \n",
    "                                                                           equipment_df, \n",
    "                                                                           configuration_col,\n",
    "                                                                           data_dict, \n",
    "                                                                           data_keys,\n",
    "                                                                           storage_key):\n",
    "        line_config_df = equipment_df.loc[:, configuration_col]\n",
    "        for equipIdx, cell in line_config_df.items():\n",
    "            for dKey in data_keys:\n",
    "                num_match = len(regex.findall(f'{dKey}{{e<=1}}', cell))\n",
    "                \n",
    "                if num_match > 0:\n",
    "                    # move thru each match (there may be multiple line configs in single cell)\n",
    "                    for idx in range(num_match):\n",
    "                        match = regex.search(f'{dKey}{{e<=1}}', cell, pos=idx)\n",
    "                        key_span = match.span()\n",
    "                        \n",
    "                        # find the next key match in the string to know where the value for this key ends\n",
    "                        possible_next_keys_pos = list()\n",
    "                        for next_dKey in data_keys:\n",
    "                            next_key_match = regex.search(f'{next_dKey}{{e<=1}}', cell[key_span[1]:], pos=0) \n",
    "                            if next_key_match is not None:\n",
    "                                possible_next_keys_pos.append(next_key_match.span()[0])\n",
    "                        # extract the data token from the string\n",
    "                        if len(possible_next_keys_pos) == 0:\n",
    "                            data_token = cell[key_span[0] : ]\n",
    "                        else:\n",
    "                            data_token = cell[key_span[0] : key_span[1] + min(possible_next_keys_pos)]\n",
    "                        data_token = data_token[ :-1] if data_token[-1] == '\\n' else data_token\n",
    "                        data_token = data_token.replace('\\n', '')\n",
    "                        print(data_token)\n",
    "                        val = data_token.split(self.key_val_sep)[1]\n",
    "                        val = val[1:] if val[0] == ' ' else val\n",
    "\n",
    "                        data_dict[str(idx)][dKey][equipIdx] = val\n",
    "\n",
    "        for line_num, line_data in data_dict.items():\n",
    "            if any([True if any([True if val is not None else False for val in data_list]) else False \n",
    "                    for tmp_key, data_list in line_data.items()]):\n",
    "                for dKey, values in line_data.items():\n",
    "                    key = f'{storage_key}_{line_num}_{dKey}'\n",
    "                    equipment_df[key] = values \n",
    "        \n",
    "    def extract_line_config_data_from_separated_cells(self, \n",
    "                                                      equipment_df, \n",
    "                                                      configuration_cols,\n",
    "                                                      data_dict, \n",
    "                                                      data_keys,\n",
    "                                                      storage_key):\n",
    "        line_config_df = equipment_df.loc[:, configuration_cols]\n",
    "        for equipIdx, row in line_config_df.iterrows():\n",
    "            for dKey, col in zip(data_dict['0'].keys(), line_config_df.columns):\n",
    "                print(line_config_df.loc[equipIdx, :])\n",
    "                print(f'{dKey}: {row[col]}')        \n",
    "                \n",
    "\n",
    "    def align_line_configuration_data(self, group_key, max_line_types=2, type_key=None): # TODO\n",
    "        \n",
    "        pdf_data_keys    = self.sections['equipment specifications'][f'{group_key} keys']\n",
    "        equipment_df = self.sections['equipment specifications']['data']\n",
    "        \n",
    "        if 'separated' in group_key:\n",
    "            storage_key = f\"{type_key.split(' ')[0]}_config\" \n",
    "            storage_data_keys = [self.sections['equipment specifications'][config_group_key] \n",
    "                                 for config_group_key in self.sections['equipment specifications'].keys() \n",
    "                                 if type_key in config_group_key][0]\n",
    "            configuration_cols = list()\n",
    "            for dKey in pdf_data_keys:\n",
    "                config_col_match_scores = [(col, levenshtein.normalized_similarity(col, dKey)) for col in equipment_df.columns]\n",
    "                scores = np.array([score for _, score in config_col_match_scores])\n",
    "                config_col = config_col_match_scores[np.argmax(scores)][0]    \n",
    "                configuration_cols.append(config_col)\n",
    "        else:\n",
    "            storage_key = f\"{group_key.split(' ')[0]}_config\"\n",
    "            storage_data_keys = pdf_data_keys\n",
    "            configuration_cols = [col for col in equipment_df if group_key in col.lower()]\n",
    "            \n",
    "        data_dict = dict()\n",
    "        for idx in range(max_line_types): \n",
    "            data_dict[str(idx)] = dict()\n",
    "            for dKey in storage_data_keys:\n",
    "                data_dict[str(idx)][dKey] = [None for k in range(equipment_df.shape[0])]\n",
    "\n",
    "        if 'separated' in group_key:\n",
    "            self.extract_line_config_data_from_separated_cells(equipment_df,\n",
    "                                                               configuration_cols,\n",
    "                                                               data_dict,\n",
    "                                                               pdf_data_keys,\n",
    "                                                               storage_key)\n",
    "        else:\n",
    "            self.extract_line_config_data_from_cells_containing_all_key_value_pairs(equipment_df, \n",
    "                                                                                    configuration_cols[0],\n",
    "                                                                                    data_dict, \n",
    "                                                                                    pdf_data_keys,\n",
    "                                                                                    storage_key,)\n",
    "           \n",
    "    def get_exhibit_name(self):\n",
    "        for text_container in self.text_containers[0]:\n",
    "            text = text_container.get_text()\n",
    "            if 'exhibit' in text.lower():\n",
    "                pattern = regex.compile(r'^\\s+')\n",
    "                exhibit = pattern.sub('', text.lower().replace('exhibit', '').replace('\\n', ''))\n",
    "                self.exhibit = exhibit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ocr_pdf_path  = Path('amendments/New_Exhibit_Redacted_docTR.pdf')\n",
    "new_orig_pdf_path = Path('amendments/New_Exhibit_Redacted.pdf')\n",
    "old_ocr_pdf_path  = Path('amendments/Old_Exhibit_Redacted_docTR.pdf')\n",
    "old_orig_pdf_path = Path('amendments/Old_Exhibit_Redacted.pdf')\n",
    "\n",
    "config_path = Path(r'C:\\Users\\Dalton\\Documents\\personal_records\\apex_consulting\\materials_and_amendments_OCR\\configs\\atc_extra_info_config.yaml')\n",
    "\n",
    "det_arch_options  = ['linknet_resnet18',\n",
    "                     'linknet_resnet34',\n",
    "                     'linknet_resnet50',\n",
    "                     'db_resnet50',\n",
    "                     'db_mobilenet_v3_large',\n",
    "                     'fast_tiny',\n",
    "                     'fast_small',\n",
    "                     'fast_base',]\n",
    "\n",
    "reco_arch_options = ['crnn_vgg16_bn',\n",
    "                     'crnn_mobilenet_v3_small',\n",
    "                     'crnn_mobilenet_v3_large',\n",
    "                     'sar_resnet31',\n",
    "                     'master',\n",
    "                     'vitstr_small',\n",
    "                     'vitstr_base',\n",
    "                     'parseq',]\n",
    "\n",
    "predictor = ocr_predictor(det_arch='fast_base', reco_arch='crnn_vgg16_bn', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_exhibit = ATC_amendment(new_orig_pdf_path, new_ocr_pdf_path, config_path, ':')\n",
    "new_exhibit.get_text_lines_from_original()\n",
    "new_exhibit.run_ocr(predictor)\n",
    "new_exhibit.get_text_lines_from_ocr()\n",
    "new_exhibit.organize_text_lines_by_row_and_column()\n",
    "new_exhibit.get_section_bounds()\n",
    "new_exhibit.fill_implicit_keys('ground space requirements', left_mult=2, right_mult=2)\n",
    "new_exhibit.extract_table_data()\n",
    "new_exhibit.extract_text_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qty: 3\n",
      "Type: Coax\n",
      "Diameter: 1/2\" Coax\n",
      "Azimuth/Sector: 1/1/1\n",
      "Qty: 6\n",
      "Type: Coax\n",
      "Diameter: 1 5/8\"Coax\n",
      "Azimuth/Sector: 2/2/2\n",
      "Qty: 1\n",
      "Type: Fiber/Hybrid\n",
      "Diameter: 1 5/8\"(1.63\"-41.3mm) Fiber\n",
      "Azimuth/Sector: 1/0/0\n",
      "Qty: 3\n",
      "Type: Coax\n",
      "Diameter: 1/4\" Coax\n",
      "Azimuth/Sector: 1/1/1\n",
      "Qty: 3\n",
      "Type: Hard Line\n",
      "Diameter: 1/8\" HardLine\n",
      "Azimuth/Sector: 2/1\n",
      "Qty: 4\n",
      "Qty: 4\n",
      "Type: Control Cable\n",
      "Type: Control Cable\n",
      "Diameter: 0.31\" (7.8mm) Cable\n",
      "Diameter: 0.31\" (7.8mm) Cable\n",
      "Azimuth/Sector: 4\n",
      "Azimuth/Sector: 4\n",
      "Qty: 2\n",
      "Qty: 2\n",
      "Type: Control Cable\n",
      "Type: Control Cable\n",
      "Diameter: 0.31\" (7.8mm) Cable\n",
      "Diameter: 0.31\" (7.8mm) Cable\n",
      "Azimuth/Sector: 2\n",
      "Azimuth/Sector: 2\n",
      "Qty: 1\n",
      "Qty: 1\n",
      "Type: 2\" conduit\n",
      "Type: 2\" conduit\n",
      "containing:-;\n",
      "containing:-;\n",
      "Azimuth/Sector: 1\n",
      "Azimuth/Sector: 1\n"
     ]
    }
   ],
   "source": [
    "new_exhibit.align_line_configuration_data(group_key = 'line configuration'   , max_line_types=2)\n",
    "new_exhibit.align_line_configuration_data(group_key = 'conduit configuration', max_line_types=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model #</th>\n",
       "      <th>Dimensions HxWxD</th>\n",
       "      <th>Weight (lbs.)</th>\n",
       "      <th>Location</th>\n",
       "      <th>RAD Center AGL</th>\n",
       "      <th>Tip Height</th>\n",
       "      <th>Base Height</th>\n",
       "      <th>Mount Type</th>\n",
       "      <th>...</th>\n",
       "      <th>line_config_1_Diameter</th>\n",
       "      <th>line_config_1_Azimuth/Sector</th>\n",
       "      <th>conduit_config_0_Qty</th>\n",
       "      <th>conduit_config_0_Type</th>\n",
       "      <th>conduit_config_0_containing</th>\n",
       "      <th>conduit_config_0_Azimuth/Sector</th>\n",
       "      <th>conduit_config_1_Qty</th>\n",
       "      <th>conduit_config_1_Type</th>\n",
       "      <th>conduit_config_1_containing</th>\n",
       "      <th>conduit_config_1_Azimuth/Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPS</td>\n",
       "      <td>Generic</td>\n",
       "      <td>GPS</td>\n",
       "      <td>12\" x 9\" x 6\"</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Ground</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PANEL</td>\n",
       "      <td>RFS</td>\n",
       "      <td>APXVAA24_43-U-\\nA20</td>\n",
       "      <td>96\" x 24\" x 8.5\"</td>\n",
       "      <td>101.4</td>\n",
       "      <td>Tower</td>\n",
       "      <td>180.0'</td>\n",
       "      <td>184.0'</td>\n",
       "      <td>176.0'</td>\n",
       "      <td>Side Arm</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PANEL</td>\n",
       "      <td>CellMax</td>\n",
       "      <td>CMA-B/6521/E0-6</td>\n",
       "      <td>81.1\" x 7.7\" x 4.8\"</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Tower</td>\n",
       "      <td>180.0'</td>\n",
       "      <td>183.4'</td>\n",
       "      <td>176.6'</td>\n",
       "      <td>Side Arm</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTA</td>\n",
       "      <td>RFS</td>\n",
       "      <td>ATM1900D-1CWA</td>\n",
       "      <td>8.6\" x 10\" x 2.6\"</td>\n",
       "      <td>8.4</td>\n",
       "      <td>Tower</td>\n",
       "      <td>180.0'</td>\n",
       "      <td>180.4'</td>\n",
       "      <td>179.6'</td>\n",
       "      <td>Side Arm</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RRU/RRH</td>\n",
       "      <td>Ericsson</td>\n",
       "      <td>Radio 4478 B71</td>\n",
       "      <td>15\" x 13.2\" x 7.4\"</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Tower</td>\n",
       "      <td>180.0'</td>\n",
       "      <td>180.6'</td>\n",
       "      <td>179.4'</td>\n",
       "      <td>Side Arm</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RRU/RRH</td>\n",
       "      <td>Ericsson</td>\n",
       "      <td>RRU22</td>\n",
       "      <td>20.2\" x 13.2\" x 6.9\"</td>\n",
       "      <td>52.9</td>\n",
       "      <td>Tower</td>\n",
       "      <td>180.0'</td>\n",
       "      <td>180.8'</td>\n",
       "      <td>179.2'</td>\n",
       "      <td>Side Arm</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2\" conduit</td>\n",
       "      <td>-;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2\" conduit</td>\n",
       "      <td>-;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RRU/RRH</td>\n",
       "      <td>Ericsson</td>\n",
       "      <td>RRU22</td>\n",
       "      <td>20.2\" x 13.2\" x 6.9\"</td>\n",
       "      <td>52.9</td>\n",
       "      <td>Tower</td>\n",
       "      <td>180.0'</td>\n",
       "      <td>180.8'</td>\n",
       "      <td>179.2'</td>\n",
       "      <td>Side Arm</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DISH-HP</td>\n",
       "      <td>Commscope</td>\n",
       "      <td>USX6-6W</td>\n",
       "      <td>6.23' x 6.23' x 4.32'</td>\n",
       "      <td>198.0</td>\n",
       "      <td>Tower</td>\n",
       "      <td>155.0'</td>\n",
       "      <td>158.1'</td>\n",
       "      <td>151.9'</td>\n",
       "      <td>Pole Mount</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DISH-HP</td>\n",
       "      <td>Commscope</td>\n",
       "      <td>USX10-11W</td>\n",
       "      <td>10' x -' x -'</td>\n",
       "      <td>579.8</td>\n",
       "      <td>Tower</td>\n",
       "      <td>155.0'</td>\n",
       "      <td>160.0'</td>\n",
       "      <td>150.0'</td>\n",
       "      <td>Pole Mount</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Radio/ODU</td>\n",
       "      <td>Ceragon</td>\n",
       "      <td>RFU-D</td>\n",
       "      <td>9.1\" x 9.2\" x 3.9\"</td>\n",
       "      <td>14.3</td>\n",
       "      <td>Tower</td>\n",
       "      <td>155.0'</td>\n",
       "      <td>155.4'</td>\n",
       "      <td>154.6'</td>\n",
       "      <td>Pole Mount</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31\" (7.8mm) Cable</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Radio/ODU</td>\n",
       "      <td>Ceragon</td>\n",
       "      <td>RFU-D</td>\n",
       "      <td>9.1\" x 9.2\" x 3.9\"</td>\n",
       "      <td>14.3</td>\n",
       "      <td>Tower</td>\n",
       "      <td>155.0'</td>\n",
       "      <td>155.4'</td>\n",
       "      <td>154.6'</td>\n",
       "      <td>Pole Mount</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31\" (7.8mm) Cable</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DISH-HP</td>\n",
       "      <td>Commscope</td>\n",
       "      <td>SHPX4-6W</td>\n",
       "      <td>4.23' x -' x -'</td>\n",
       "      <td>70.5</td>\n",
       "      <td>Tower</td>\n",
       "      <td>125.0'</td>\n",
       "      <td>127.1'</td>\n",
       "      <td>122.9'</td>\n",
       "      <td>Pole Mount</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows  37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Type Manufacturer              Model #       Dimensions HxWxD  \\\n",
       "0         GPS      Generic                  GPS          12\" x 9\" x 6\"   \n",
       "1       PANEL          RFS  APXVAA24_43-U-\\nA20       96\" x 24\" x 8.5\"   \n",
       "2       PANEL      CellMax      CMA-B/6521/E0-6    81.1\" x 7.7\" x 4.8\"   \n",
       "3         TTA          RFS        ATM1900D-1CWA      8.6\" x 10\" x 2.6\"   \n",
       "4     RRU/RRH     Ericsson       Radio 4478 B71     15\" x 13.2\" x 7.4\"   \n",
       "5     RRU/RRH     Ericsson                RRU22   20.2\" x 13.2\" x 6.9\"   \n",
       "6     RRU/RRH     Ericsson                RRU22   20.2\" x 13.2\" x 6.9\"   \n",
       "7     DISH-HP    Commscope              USX6-6W  6.23' x 6.23' x 4.32'   \n",
       "8     DISH-HP    Commscope            USX10-11W          10' x -' x -'   \n",
       "9   Radio/ODU      Ceragon                RFU-D     9.1\" x 9.2\" x 3.9\"   \n",
       "10  Radio/ODU      Ceragon                RFU-D     9.1\" x 9.2\" x 3.9\"   \n",
       "11    DISH-HP    Commscope             SHPX4-6W        4.23' x -' x -'   \n",
       "\n",
       "   Weight (lbs.) Location RAD Center AGL Tip Height Base Height  Mount Type  \\\n",
       "0           10.0   Ground            N/A        N/A         N/A         N/A   \n",
       "1          101.4    Tower         180.0'     184.0'      176.0'    Side Arm   \n",
       "2           35.0    Tower         180.0'     183.4'      176.6'    Side Arm   \n",
       "3            8.4    Tower         180.0'     180.4'      179.6'    Side Arm   \n",
       "4           60.0    Tower         180.0'     180.6'      179.4'    Side Arm   \n",
       "5           52.9    Tower         180.0'     180.8'      179.2'    Side Arm   \n",
       "6           52.9    Tower         180.0'     180.8'      179.2'    Side Arm   \n",
       "7          198.0    Tower         155.0'     158.1'      151.9'  Pole Mount   \n",
       "8          579.8    Tower         155.0'     160.0'      150.0'  Pole Mount   \n",
       "9           14.3    Tower         155.0'     155.4'      154.6'  Pole Mount   \n",
       "10          14.3    Tower         155.0'     155.4'      154.6'  Pole Mount   \n",
       "11          70.5    Tower         125.0'     127.1'      122.9'  Pole Mount   \n",
       "\n",
       "    ... line_config_1_Diameter line_config_1_Azimuth/Sector  \\\n",
       "0   ...                   None                         None   \n",
       "1   ...                   None                         None   \n",
       "2   ...                   None                         None   \n",
       "3   ...                   None                         None   \n",
       "4   ...                   None                         None   \n",
       "5   ...                   None                         None   \n",
       "6   ...                   None                         None   \n",
       "7   ...                   None                         None   \n",
       "8   ...                   None                         None   \n",
       "9   ...    0.31\" (7.8mm) Cable                            4   \n",
       "10  ...    0.31\" (7.8mm) Cable                            2   \n",
       "11  ...                   None                         None   \n",
       "\n",
       "   conduit_config_0_Qty conduit_config_0_Type conduit_config_0_containing  \\\n",
       "0                  None                  None                        None   \n",
       "1                  None                  None                        None   \n",
       "2                  None                  None                        None   \n",
       "3                  None                  None                        None   \n",
       "4                  None                  None                        None   \n",
       "5                     1            2\" conduit                          -;   \n",
       "6                  None                  None                        None   \n",
       "7                  None                  None                        None   \n",
       "8                  None                  None                        None   \n",
       "9                  None                  None                        None   \n",
       "10                 None                  None                        None   \n",
       "11                 None                  None                        None   \n",
       "\n",
       "   conduit_config_0_Azimuth/Sector conduit_config_1_Qty conduit_config_1_Type  \\\n",
       "0                             None                 None                  None   \n",
       "1                             None                 None                  None   \n",
       "2                             None                 None                  None   \n",
       "3                             None                 None                  None   \n",
       "4                             None                 None                  None   \n",
       "5                                1                    1            2\" conduit   \n",
       "6                             None                 None                  None   \n",
       "7                             None                 None                  None   \n",
       "8                             None                 None                  None   \n",
       "9                             None                 None                  None   \n",
       "10                            None                 None                  None   \n",
       "11                            None                 None                  None   \n",
       "\n",
       "   conduit_config_1_containing conduit_config_1_Azimuth/Sector  \n",
       "0                         None                            None  \n",
       "1                         None                            None  \n",
       "2                         None                            None  \n",
       "3                         None                            None  \n",
       "4                         None                            None  \n",
       "5                           -;                               1  \n",
       "6                         None                            None  \n",
       "7                         None                            None  \n",
       "8                         None                            None  \n",
       "9                         None                            None  \n",
       "10                        None                            None  \n",
       "11                        None                            None  \n",
       "\n",
       "[12 rows x 37 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_exhibit.sections['ground space requirements']['data']\n",
    "new_exhibit.sections['backup power requirements']['data']\n",
    "new_exhibit.sections['utility requirements']['data']\n",
    "new_exhibit.sections['transmitter & receiver specifications']['data']\n",
    "new_exhibit.sections['equipment specifications']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "storing text from OCR on page 0:\n",
      "\"exhibit a-3\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"total lease area sq.ft:21600 primary contiguous lease area l:1200 w:1800 h:1000 sq.ft: 216.00)\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"ground space requirements\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"concrete pad 1000 16.00\" nia 160.00]\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"outside primary lease area nia nia nia sq. ft: n/a|\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"backup power requirements\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"generator: nia capacity(kw): n/a fuel tank size(gal): n/a fuel type: nia fuel tank setback{radiu:\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"utility requirements\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"power provided by: utiity company direct\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"telco/lnterconnect:\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"ua\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"transmitter & receiver specifications\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"type: n/a quantity: nia tx power(watts): nia erp(watts): n/a\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"equipment specifications\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"type panel panel tta rrurrh rrurrh rrurrh\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"manufacturer cellmax rfs rfs ericsson ericsson ericsson\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"model # cmabigs21/e06 | apxvaa24_43-u-a20| atm1900d-1cwa rruz2 rru22 radio 4478 b71\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"dimensions hxwxd | 81.1'x7.7'x48 | 96'x24'x85 | 86x10x26 | 202x132 x69\" | 02x 132x689\" | 16x 132 x74\"\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"[weight(ibs.) 350 1014 84 529 529 600\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"location tower, tower, tower tower tower tower\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"rad center agl 180.0\" 180.0\" 180.0 180.0\" 180.0\" 180.0\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"equipment tip 1834 1840 1804 1808 1808 180.6\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"equipment base 1766 1760 1796 1792 1792 179.4\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"eight\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"mount type side am side am side am side am side am side am\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"quantity 6 3 3 1 2 3\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"rzimuths/dir. of 60/80/300 6011807300 6011807300 60 180/300 6011801300\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"quant. per\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"quant. per cor na 111 nn 1 n nn\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"(rx frequency mhz mhz na mhz mhz na\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"nits\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"tx frequency 215517351740 668-638 nia 1740 1740 nia\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"1930-1945.2145- 21452155, 1736 | 2145-2155,1736-\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"rx frequency 175521352140 622642 na 2140 2140 na\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"using unlicensed no no no no o no\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"1850-1865,1745- 74517552135 | 1745-1756.2135-\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"frequencies?\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"equipment gain 18.31 18.7/192 132/136 2 na na na\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"total # of lines 6 3 1 2 3 3\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"line quant. per\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"fliinnee qquuaanntt. ppeerr na nn 11000 2 n nn\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"line type coax coax fiberfhybrid conduit hard line coax\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"line diameter size 15/8\" coax 112\" coax 15/et(les aiim) 2 conduit 1/8\" hard line 114 coax\"\n",
      "\n",
      "storing text from OCR on page 0:\n",
      "\"line configuration na na na na na na\"\n",
      "page = 0, ypos=7.38e-07, type=<class 'pdfminer.layout.LTFigure'>\n",
      "\n",
      "storing text from OCR on page 1:\n",
      "\"equipment specifications\"\n",
      "page = 1, ypos=-5.348e-06, type=<class 'pdfminer.layout.LTFigure'>\n"
     ]
    }
   ],
   "source": [
    "old_exhibit = ATC_amendment(old_orig_pdf_path, old_ocr_pdf_path, config_path, ':')\n",
    "old_exhibit.get_text_lines_from_original()\n",
    "old_exhibit.get_text_lines_from_ocr()\n",
    "old_exhibit.organize_text_lines_by_row_and_column()\n",
    "old_exhibit.get_section_bounds()\n",
    "old_exhibit.fill_implicit_keys('ground space requirements', left_mult=2, right_mult=2)\n",
    "old_exhibit.extract_table_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total lease area sq.ft: 21600\n",
      "primary contiguous lease area - l: 1200\n",
      "primary contiguous lease area - w: 1800\n",
      "primary contiguous lease area - h: 1000\n",
      "primary contiguous lease area - sq.ft: 216.00)\n",
      "concrete pad - l: 1000\n",
      "concrete pad - w: 16.00\"\n",
      "concrete pad - h: nia\n",
      "concrete pad - sq.ft: 160.00]\n",
      "outside primary lease area - l: nia\n",
      "outside primary lease area - w: nia\n",
      "outside primary lease area - h: nia\n",
      "outside primary lease area - sq. ft: n/a\n",
      "generator: nia\n",
      "capacity(kw): n/a\n",
      "fuel tank size(gal): n/a\n",
      "fuel type: nia\n",
      "fuel tank setback{radiu: None\n",
      "power provided by: utiity company direct\n",
      "telco/lnterconnect: ua\n",
      "telco/lnterconnect: ua\n",
      "type: n/a\n",
      "quantity: nia\n",
      "tx power(watts): nia\n",
      "erp(watts): n/a\n",
      "type Line Type\n",
      "manufacturer Quant. Per Azimuth/Sector\n",
      "model # Model #\n",
      "dimensions hxwxd Dimensions HxWxD\n",
      "[weight(ibs.) Using Unlicensed Frequencies?\n",
      "location Total # of Lines\n",
      "rad center agl RAD Center AGL\n",
      "equipment tip Equipment Tip Height\n",
      "equipment base eight Equipment Base Height\n",
      "mount type Mount Type\n",
      "quantity Line Quant. Per Azimuth/Sector\n",
      "rzimuths/dir. of Azimuths/Dir. of Radiation\n",
      "qquuaanntt.. ppeerr cor Manufacturer\n",
      "(rx frequency nits TX/RX Frequency Units\n",
      "tx frequency Equipment Gain\n",
      "rx frequency Line Configuration\n",
      "using unlicensed Weight(lbs.)\n",
      "frequencies? TX Frequency\n",
      "equipment gain Line Diameter Size\n",
      "total # of lines Location\n",
      "fliinnee qquuaanntt. ppeerr Quantity\n",
      "line type Type\n",
      "line diameter size RX Frequency\n",
      "line configuration \n",
      "\n",
      "\"TX Frequency\" contained the wrong number of columns in the line.\n",
      "\n",
      "\"RX Frequency\" contained the wrong number of columns in the line.\n"
     ]
    }
   ],
   "source": [
    "old_exhibit.extract_text_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1     0\n",
      "2     4\n",
      "3     0\n",
      "4     1\n",
      "5     0\n",
      "6     6\n",
      "7     3\n",
      "8     1\n",
      "9     2\n",
      "10    3\n",
      "11    3\n",
      "Name: Total # of Lines, dtype: object\n",
      "0         Coax\n",
      "1          N/A\n",
      "2     Multiple\n",
      "3          N/A\n",
      "4         Coax\n",
      "5          N/A\n",
      "6           na\n",
      "7           nn\n",
      "8        11000\n",
      "9            2\n",
      "10           n\n",
      "11          nn\n",
      "Name: Line Type, dtype: object\n",
      "0      0.29\" (7.2mm) RG-8\n",
      "1                     N/A\n",
      "2     See Config. Summary\n",
      "3                     N/A\n",
      "4      0.29\" (7.2mm) RG-8\n",
      "5                     N/A\n",
      "6          18.31 18.7/192\n",
      "7                 132/136\n",
      "8                       2\n",
      "9                      na\n",
      "10                     na\n",
      "11                     na\n",
      "Name: Line Diameter Size, dtype: object\n",
      "0                       1\n",
      "1                     N/A\n",
      "2     See Config. Summary\n",
      "3                     N/A\n",
      "4                       1\n",
      "5                     N/A\n",
      "6       wrong_num_columns\n",
      "7       wrong_num_columns\n",
      "8       wrong_num_columns\n",
      "9       wrong_num_columns\n",
      "10      wrong_num_columns\n",
      "11      wrong_num_columns\n",
      "Name: Line Quant. Per Azimuth/Sector, dtype: object\n",
      "0                                                   N/A\n",
      "1                                                   N/A\n",
      "2     2 - Control Cable;\\n0.31\" (7.8mm) Cable;\\n2\\n2...\n",
      "3                                                   N/A\n",
      "4                                                   N/A\n",
      "5                                                   N/A\n",
      "6                                                  coax\n",
      "7                                                  coax\n",
      "8                                          fiberfhybrid\n",
      "9                                              conduit\n",
      "10                                            hard line\n",
      "11                                                 coax\n",
      "Name: Line Configuration, dtype: object\n",
      "Total # of Lines                                   1\n",
      "Line Type                                       Coax\n",
      "Line Diameter Size                0.29\" (7.2mm) RG-8\n",
      "Line Quant. Per Azimuth/Sector                     1\n",
      "Line Configuration                               N/A\n",
      "Name: 0, dtype: object\n",
      "Total # of Lines                    0\n",
      "Line Type                         N/A\n",
      "Line Diameter Size                N/A\n",
      "Line Quant. Per Azimuth/Sector    N/A\n",
      "Line Configuration                N/A\n",
      "Name: 1, dtype: object\n",
      "Total # of Lines                                                                  4\n",
      "Line Type                                                                  Multiple\n",
      "Line Diameter Size                                              See Config. Summary\n",
      "Line Quant. Per Azimuth/Sector                                  See Config. Summary\n",
      "Line Configuration                2 - Control Cable;\\n0.31\" (7.8mm) Cable;\\n2\\n2...\n",
      "Name: 2, dtype: object\n",
      "Total # of Lines                    0\n",
      "Line Type                         N/A\n",
      "Line Diameter Size                N/A\n",
      "Line Quant. Per Azimuth/Sector    N/A\n",
      "Line Configuration                N/A\n",
      "Name: 3, dtype: object\n",
      "Total # of Lines                                   1\n",
      "Line Type                                       Coax\n",
      "Line Diameter Size                0.29\" (7.2mm) RG-8\n",
      "Line Quant. Per Azimuth/Sector                     1\n",
      "Line Configuration                               N/A\n",
      "Name: 4, dtype: object\n",
      "Total # of Lines                    0\n",
      "Line Type                         N/A\n",
      "Line Diameter Size                N/A\n",
      "Line Quant. Per Azimuth/Sector    N/A\n",
      "Line Configuration                N/A\n",
      "Name: 5, dtype: object\n",
      "Total # of Lines                                  6\n",
      "Line Type                                        na\n",
      "Line Diameter Size                   18.31 18.7/192\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                             coax\n",
      "Name: 6, dtype: object\n",
      "Total # of Lines                                  3\n",
      "Line Type                                        nn\n",
      "Line Diameter Size                          132/136\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                             coax\n",
      "Name: 7, dtype: object\n",
      "Total # of Lines                                  1\n",
      "Line Type                                     11000\n",
      "Line Diameter Size                                2\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                     fiberfhybrid\n",
      "Name: 8, dtype: object\n",
      "Total # of Lines                                  2\n",
      "Line Type                                         2\n",
      "Line Diameter Size                               na\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                         conduit\n",
      "Name: 9, dtype: object\n",
      "Total # of Lines                                  3\n",
      "Line Type                                         n\n",
      "Line Diameter Size                               na\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                        hard line\n",
      "Name: 10, dtype: object\n",
      "Total # of Lines                                  3\n",
      "Line Type                                        nn\n",
      "Line Diameter Size                               na\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                             coax\n",
      "Name: 11, dtype: object\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "Total # of Lines Total # of Lines\n",
      "Line Type Line Type\n",
      "Line Diameter Size Line Diameter Size\n",
      "Line Quant. Per Azimuth/Sector Line Quant. Per Azimuth/Sector\n",
      "Line Configuration Line Configuration\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "0 Total # of Lines\n",
      "1 Line Type\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "Qty: Total # of Lines\n",
      "Type: Line Type\n",
      "Diameter: Line Diameter Size\n",
      "Azimuth/Sector: Line Quant. Per Azimuth/Sector\n",
      "3\n",
      "nn\n",
      "na\n",
      "wrong_num_columns\n",
      "Qty: 3\n",
      "Type: nn\n",
      "Diameter: na\n",
      "Azimuth/Sector: wrong_num_columns\n",
      "Total # of Lines                                  3\n",
      "Line Type                                        nn\n",
      "Line Diameter Size                               na\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                             coax\n",
      "Name: 11, dtype: object\n",
      "Qty: 3\n",
      "Total # of Lines                                  3\n",
      "Line Type                                        nn\n",
      "Line Diameter Size                               na\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                             coax\n",
      "Name: 11, dtype: object\n",
      "Type: nn\n",
      "Total # of Lines                                  3\n",
      "Line Type                                        nn\n",
      "Line Diameter Size                               na\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                             coax\n",
      "Name: 11, dtype: object\n",
      "Diameter: na\n",
      "Total # of Lines                                  3\n",
      "Line Type                                        nn\n",
      "Line Diameter Size                               na\n",
      "Line Quant. Per Azimuth/Sector    wrong_num_columns\n",
      "Line Configuration                             coax\n",
      "Name: 11, dtype: object\n",
      "Azimuth/Sector: wrong_num_columns\n"
     ]
    }
   ],
   "source": [
    "old_exhibit.align_line_configuration_data(group_key = 'separated configuration', max_line_types=2, type_key = 'line')\n",
    "old_exhibit.align_line_configuration_data(group_key = 'separated configuration', max_line_types=2, type_key = 'conduit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model #</th>\n",
       "      <th>Dimensions HxWxD</th>\n",
       "      <th>Weight(lbs.)</th>\n",
       "      <th>Location</th>\n",
       "      <th>RAD Center AGL</th>\n",
       "      <th>Equipment Tip Height</th>\n",
       "      <th>Equipment Base Height</th>\n",
       "      <th>...</th>\n",
       "      <th>TX/RX Frequency Units</th>\n",
       "      <th>TX Frequency</th>\n",
       "      <th>RX Frequency</th>\n",
       "      <th>Using Unlicensed Frequencies?</th>\n",
       "      <th>Equipment Gain</th>\n",
       "      <th>Total # of Lines</th>\n",
       "      <th>Line Quant. Per Azimuth/Sector</th>\n",
       "      <th>Line Type</th>\n",
       "      <th>Line Diameter Size</th>\n",
       "      <th>Line Configuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>DISH-HP</td>\n",
       "      <td>RFS</td>\n",
       "      <td>SB6-W60BC</td>\n",
       "      <td>6.23' x 6.23' x 2.98'</td>\n",
       "      <td>198.0</td>\n",
       "      <td>Tower</td>\n",
       "      <td>155.0'</td>\n",
       "      <td>158.1'</td>\n",
       "      <td>151.9'</td>\n",
       "      <td>...</td>\n",
       "      <td>MHz</td>\n",
       "      <td>6400</td>\n",
       "      <td>6400</td>\n",
       "      <td>No</td>\n",
       "      <td>35.7/ 36.7/ 37.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Coax</td>\n",
       "      <td>0.29\" (7.2mm) RG-8</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>DISH-HP</td>\n",
       "      <td>Commscope</td>\n",
       "      <td>USX10-11W</td>\n",
       "      <td>10.00' x -' x -'</td>\n",
       "      <td>579.8</td>\n",
       "      <td>Tower</td>\n",
       "      <td>155.0'</td>\n",
       "      <td>160.0'</td>\n",
       "      <td>150.0'</td>\n",
       "      <td>...</td>\n",
       "      <td>GHz</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Radio/ODU</td>\n",
       "      <td>Ceragon</td>\n",
       "      <td>RFU-D</td>\n",
       "      <td>9.1\" x 9.2\" x 3.9\"</td>\n",
       "      <td>14.3</td>\n",
       "      <td>Tower</td>\n",
       "      <td>155.0'</td>\n",
       "      <td>155.4'</td>\n",
       "      <td>154.6'</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>No</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4</td>\n",
       "      <td>See Config. Summary</td>\n",
       "      <td>Multiple</td>\n",
       "      <td>See Config. Summary</td>\n",
       "      <td>2 - Control Cable;\\n0.31\" (7.8mm) Cable;\\n2\\n2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Radio/ODU</td>\n",
       "      <td>Ceragon</td>\n",
       "      <td>FibeAir IP-20E</td>\n",
       "      <td>9.2\" x 9.1\" x 3.9\"</td>\n",
       "      <td>14.3</td>\n",
       "      <td>Tower</td>\n",
       "      <td>155.0'</td>\n",
       "      <td>155.4'</td>\n",
       "      <td>154.6'</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>No</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>DISH-HP</td>\n",
       "      <td>RFS</td>\n",
       "      <td>SB4-W60</td>\n",
       "      <td>4.14' x 4.14' x -'</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Tower</td>\n",
       "      <td>125.0'</td>\n",
       "      <td>127.1'</td>\n",
       "      <td>122.9'</td>\n",
       "      <td>...</td>\n",
       "      <td>MHz</td>\n",
       "      <td>6400</td>\n",
       "      <td>6400</td>\n",
       "      <td>No</td>\n",
       "      <td>32.4 / 32.7 / 33.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Coax</td>\n",
       "      <td>0.29\" (7.2mm) RG-8</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>Radio/ODU</td>\n",
       "      <td>Ceragon</td>\n",
       "      <td>FibeAir IP-20E</td>\n",
       "      <td>9.2\" x 9.1\" x 3.9\"</td>\n",
       "      <td>14.3</td>\n",
       "      <td>Tower</td>\n",
       "      <td>125.0'</td>\n",
       "      <td>125.4'</td>\n",
       "      <td>124.6'</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>No</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>na</td>\n",
       "      <td>panel</td>\n",
       "      <td>cellmax</td>\n",
       "      <td>cmabigs21/e06</td>\n",
       "      <td>81.1'x7.7'x48</td>\n",
       "      <td>350</td>\n",
       "      <td>tower,</td>\n",
       "      <td>180.0\"</td>\n",
       "      <td>na</td>\n",
       "      <td>1766</td>\n",
       "      <td>...</td>\n",
       "      <td>mhz</td>\n",
       "      <td>1930-1945.2145- 215517351740</td>\n",
       "      <td>11875505-12816355,21174450-</td>\n",
       "      <td>no</td>\n",
       "      <td>1834</td>\n",
       "      <td>6</td>\n",
       "      <td>wrong_num_columns</td>\n",
       "      <td>na</td>\n",
       "      <td>18.31 18.7/192</td>\n",
       "      <td>coax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>na</td>\n",
       "      <td>panel</td>\n",
       "      <td>rfs</td>\n",
       "      <td>apxvaa24_43-u-a20</td>\n",
       "      <td>96'x24'x85</td>\n",
       "      <td>1014</td>\n",
       "      <td>tower,</td>\n",
       "      <td>180.0\"</td>\n",
       "      <td>111</td>\n",
       "      <td>1760</td>\n",
       "      <td>...</td>\n",
       "      <td>mhz</td>\n",
       "      <td>668-638</td>\n",
       "      <td>622642</td>\n",
       "      <td>no</td>\n",
       "      <td>1840</td>\n",
       "      <td>3</td>\n",
       "      <td>wrong_num_columns</td>\n",
       "      <td>nn</td>\n",
       "      <td>132/136</td>\n",
       "      <td>coax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>na</td>\n",
       "      <td>tta</td>\n",
       "      <td>rfs</td>\n",
       "      <td>atm1900d-1cwa</td>\n",
       "      <td>86x10x26</td>\n",
       "      <td>84</td>\n",
       "      <td>tower</td>\n",
       "      <td>180.0</td>\n",
       "      <td>nn</td>\n",
       "      <td>1796</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>nia</td>\n",
       "      <td>na</td>\n",
       "      <td>no</td>\n",
       "      <td>1804</td>\n",
       "      <td>1</td>\n",
       "      <td>wrong_num_columns</td>\n",
       "      <td>11000</td>\n",
       "      <td>2</td>\n",
       "      <td>fiberfhybrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>na</td>\n",
       "      <td>rrurrh</td>\n",
       "      <td>ericsson</td>\n",
       "      <td>rruz2</td>\n",
       "      <td>202x132 x69\"</td>\n",
       "      <td>529</td>\n",
       "      <td>tower</td>\n",
       "      <td>180.0\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1792</td>\n",
       "      <td>...</td>\n",
       "      <td>mhz</td>\n",
       "      <td>21452155, 1736 1740</td>\n",
       "      <td>74512715450 2135</td>\n",
       "      <td>no</td>\n",
       "      <td>1808</td>\n",
       "      <td>2</td>\n",
       "      <td>wrong_num_columns</td>\n",
       "      <td>2</td>\n",
       "      <td>na</td>\n",
       "      <td>conduit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>na</td>\n",
       "      <td>rrurrh</td>\n",
       "      <td>ericsson</td>\n",
       "      <td>rru22</td>\n",
       "      <td>02x 132x689\"</td>\n",
       "      <td>529</td>\n",
       "      <td>tower</td>\n",
       "      <td>180.0\"</td>\n",
       "      <td>n</td>\n",
       "      <td>1792</td>\n",
       "      <td>...</td>\n",
       "      <td>mhz</td>\n",
       "      <td>2145-2155,1736- 1740</td>\n",
       "      <td>1745-12715460. 2135-</td>\n",
       "      <td>o</td>\n",
       "      <td>1808</td>\n",
       "      <td>3</td>\n",
       "      <td>wrong_num_columns</td>\n",
       "      <td>n</td>\n",
       "      <td>na</td>\n",
       "      <td>hard line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>na</td>\n",
       "      <td>rrurrh</td>\n",
       "      <td>ericsson</td>\n",
       "      <td>radio 4478 b71</td>\n",
       "      <td>16x 132 x74\"</td>\n",
       "      <td>600</td>\n",
       "      <td>tower</td>\n",
       "      <td>180.0</td>\n",
       "      <td>nn</td>\n",
       "      <td>179.4</td>\n",
       "      <td>...</td>\n",
       "      <td>na</td>\n",
       "      <td>nia</td>\n",
       "      <td>na</td>\n",
       "      <td>no</td>\n",
       "      <td>180.6</td>\n",
       "      <td>3</td>\n",
       "      <td>wrong_num_columns</td>\n",
       "      <td>nn</td>\n",
       "      <td>na</td>\n",
       "      <td>coax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type Manufacturer            Model #       Dimensions HxWxD  \\\n",
       "0   None    DISH-HP          RFS          SB6-W60BC  6.23' x 6.23' x 2.98'   \n",
       "1   None    DISH-HP    Commscope          USX10-11W       10.00' x -' x -'   \n",
       "2   None  Radio/ODU      Ceragon              RFU-D     9.1\" x 9.2\" x 3.9\"   \n",
       "3   None  Radio/ODU      Ceragon     FibeAir IP-20E     9.2\" x 9.1\" x 3.9\"   \n",
       "4   None    DISH-HP          RFS            SB4-W60     4.14' x 4.14' x -'   \n",
       "5   None  Radio/ODU      Ceragon     FibeAir IP-20E     9.2\" x 9.1\" x 3.9\"   \n",
       "6     na      panel      cellmax      cmabigs21/e06          81.1'x7.7'x48   \n",
       "7     na      panel          rfs  apxvaa24_43-u-a20             96'x24'x85   \n",
       "8     na        tta          rfs      atm1900d-1cwa               86x10x26   \n",
       "9     na     rrurrh     ericsson              rruz2           202x132 x69\"   \n",
       "10    na     rrurrh     ericsson              rru22           02x 132x689\"   \n",
       "11    na     rrurrh     ericsson     radio 4478 b71           16x 132 x74\"   \n",
       "\n",
       "   Weight(lbs.) Location RAD Center AGL Equipment Tip Height  \\\n",
       "0         198.0    Tower         155.0'               158.1'   \n",
       "1         579.8    Tower         155.0'               160.0'   \n",
       "2          14.3    Tower         155.0'               155.4'   \n",
       "3          14.3    Tower         155.0'               155.4'   \n",
       "4          77.0    Tower         125.0'               127.1'   \n",
       "5          14.3    Tower         125.0'               125.4'   \n",
       "6           350   tower,         180.0\"                   na   \n",
       "7          1014   tower,         180.0\"                  111   \n",
       "8            84    tower          180.0                   nn   \n",
       "9           529    tower         180.0\"                    1   \n",
       "10          529    tower         180.0\"                    n   \n",
       "11          600    tower          180.0                   nn   \n",
       "\n",
       "   Equipment Base Height  ... TX/RX Frequency Units  \\\n",
       "0                 151.9'  ...                   MHz   \n",
       "1                 150.0'  ...                   GHz   \n",
       "2                 154.6'  ...                   N/A   \n",
       "3                 154.6'  ...                   N/A   \n",
       "4                 122.9'  ...                   MHz   \n",
       "5                 124.6'  ...                   N/A   \n",
       "6                   1766  ...                   mhz   \n",
       "7                  1760  ...                   mhz   \n",
       "8                   1796  ...                    na   \n",
       "9                   1792  ...                   mhz   \n",
       "10                  1792  ...                   mhz   \n",
       "11                 179.4  ...                    na   \n",
       "\n",
       "                    TX Frequency                 RX Frequency  \\\n",
       "0                           6400                         6400   \n",
       "1                             11                            1   \n",
       "2                            N/A                          N/A   \n",
       "3                            N/A                          N/A   \n",
       "4                           6400                         6400   \n",
       "5                            N/A                          N/A   \n",
       "6   1930-1945.2145- 215517351740  11875505-12816355,21174450-   \n",
       "7                        668-638                       622642   \n",
       "8                            nia                           na   \n",
       "9            21452155, 1736 1740             74512715450 2135   \n",
       "10          2145-2155,1736- 1740         1745-12715460. 2135-   \n",
       "11                           nia                           na   \n",
       "\n",
       "   Using Unlicensed Frequencies?      Equipment Gain Total # of Lines  \\\n",
       "0                             No    35.7/ 36.7/ 37.3                1   \n",
       "1                             No                 N/A                0   \n",
       "2                             No                 N/A                4   \n",
       "3                             No                 N/A                0   \n",
       "4                             No  32.4 / 32.7 / 33.4                1   \n",
       "5                             No                 N/A                0   \n",
       "6                             no                1834                6   \n",
       "7                             no                1840                3   \n",
       "8                             no               1804                1   \n",
       "9                             no                1808                2   \n",
       "10                             o                1808                3   \n",
       "11                            no               180.6                3   \n",
       "\n",
       "   Line Quant. Per Azimuth/Sector Line Type   Line Diameter Size  \\\n",
       "0                               1      Coax   0.29\" (7.2mm) RG-8   \n",
       "1                             N/A       N/A                  N/A   \n",
       "2             See Config. Summary  Multiple  See Config. Summary   \n",
       "3                             N/A       N/A                  N/A   \n",
       "4                               1      Coax   0.29\" (7.2mm) RG-8   \n",
       "5                             N/A       N/A                  N/A   \n",
       "6               wrong_num_columns        na       18.31 18.7/192   \n",
       "7               wrong_num_columns        nn              132/136   \n",
       "8               wrong_num_columns     11000                    2   \n",
       "9               wrong_num_columns         2                   na   \n",
       "10              wrong_num_columns         n                   na   \n",
       "11              wrong_num_columns        nn                   na   \n",
       "\n",
       "                                   Line Configuration  \n",
       "0                                                 N/A  \n",
       "1                                                 N/A  \n",
       "2   2 - Control Cable;\\n0.31\" (7.8mm) Cable;\\n2\\n2...  \n",
       "3                                                 N/A  \n",
       "4                                                 N/A  \n",
       "5                                                 N/A  \n",
       "6                                                coax  \n",
       "7                                                coax  \n",
       "8                                        fiberfhybrid  \n",
       "9                                            conduit  \n",
       "10                                          hard line  \n",
       "11                                               coax  \n",
       "\n",
       "[12 rows x 24 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_exhibit.sections['ground space requirements']['data']\n",
    "old_exhibit.sections['backup power requirements']['data']\n",
    "old_exhibit.sections['utility requirements']['data']\n",
    "old_exhibit.sections['transmitter & receiver specifications']['data']\n",
    "old_exhibit.sections['equipment specifications']['data']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
